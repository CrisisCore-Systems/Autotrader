# üõ°Ô∏è Security & Configuration Governance - Implementation Guide

**Project:** AutoTrader Hidden Gem Scanner  
**Implementation Date:** October 9, 2025  
**Version:** 2.0.0

---

## üìã Table of Contents

1. [Overview](#overview)
2. [What Was Implemented](#what-was-implemented)
3. [Quick Start](#quick-start)
4. [Validation Tools](#validation-tools)
5. [CI/CD Integration](#cicd-integration)
6. [Pre-Commit Hooks](#pre-commit-hooks)
7. [Configuration Files](#configuration-files)
8. [Troubleshooting](#troubleshooting)
9. [Maintenance](#maintenance)

---

## üéØ Overview

This implementation addresses **all critical and high-priority security concerns** identified in the security audit:

- ‚úÖ GitHub Actions security hardening (already excellent)
- ‚úÖ Secret scanning (Gitleaks + TruffleHog)
- ‚úÖ Dependency review and vulnerability scanning
- ‚úÖ Enhanced Semgrep rules (60+ custom rules)
- ‚úÖ Prompt contract validation with schemas
- ‚úÖ Alert configuration governance
- ‚úÖ LLM configuration with cost controls
- ‚úÖ Artifact provenance tracking
- ‚úÖ Notebook execution safety
- ‚úÖ Docker hardening (already done)

**Result:** Production-ready enterprise security posture.

---

## üöÄ What Was Implemented

### 1. Prompt Contract Validation ‚ú® NEW

**Problem:** LLM outputs could drift without detection, causing downstream failures.

**Solution:**
- JSON schemas for each prompt type
- Schema version tracking
- `additionalProperties: false` to reject extra keys
- Golden test fixtures for regression testing
- CI validation on every commit

**Files Created:**
```
schemas/prompt_outputs/
‚îú‚îÄ‚îÄ narrative_analyzer.json       # Schema for narrative analysis
‚îî‚îÄ‚îÄ contract_safety.json          # Schema for contract safety checks

tests/fixtures/prompt_outputs/
‚îú‚îÄ‚îÄ narrative_analyzer_golden.json
‚îî‚îÄ‚îÄ contract_safety_golden.json

scripts/validate_prompt_contracts.py  # Validator tool
```

**Usage:**
```bash
# Validate all prompts
python scripts/validate_prompt_contracts.py

# Validate specific prompt
python scripts/validate_prompt_contracts.py --prompt narrative_analyzer

# Create new prompt schema template
python scripts/validate_prompt_contracts.py --create-fixture new_prompt
```

### 2. Enhanced LLM Configuration ‚ú® NEW

**Problem:** No cost tracking, fallback chains, or rate limiting for LLM calls.

**Solution:**
- Cost per 1K tokens for each model ($0.00015 - $0.03)
- Fallback chains (3 providers per route)
- Budget caps (daily, per-job, per-route)
- Rate limiting per provider
- Exponential backoff with jitter
- Circuit breaker pattern
- PII redaction in audit logs

**File:** `configs/llm_enhanced.yaml`

**Key Features:**
```yaml
providers:
  gpt-mid:
    cost_per_1k_input: 0.0025
    cost_per_1k_output: 0.01

routes:
  narrative_summary:
    primary: gpt-mid
    fallback: [claude-smart, gpt-small]
    max_retries: 2
    timeout_seconds: 30

budget:
  daily_usd_cap: 15.00
  alert_at_percent: 80
```

### 3. Artifact Governance ‚ú® NEW

**Problem:** Generated artifacts lacked provenance, security, and version tracking.

**Solution:**
- Comprehensive metadata schema (25+ fields)
- Secure Jinja2 templating (autoescaping, CSP)
- Generation ID (UUID v4)
- Source commit tracking
- SHA-256 checksums
- Provenance trail
- Retention policies

**Files Created:**
```
schemas/artifact_metadata.json         # Metadata schema
scripts/generate_artifact.py           # Secure generator
```

**Usage:**
```python
from scripts.generate_artifact import ArtifactGenerator

gen = ArtifactGenerator(
    artifact_type="dashboard",
    template_name="dashboard.html.j2",
    output_path=Path("artifacts/dashboard.html"),
    classification="internal"
)

metadata = gen.generate_metadata(
    input_window={"start": "...", "end": "..."},
    tags=["dashboard", "daily"],
    retention_days=90
)

rendered = gen.render_template(context, metadata)
gen.save_artifact(rendered, metadata)
```

### 4. Notebook Execution Safety ‚ú® NEW

**Problem:** Notebooks only checked for loadability, not actual execution success.

**Solution:**
- Papermill CI execution with 30min timeout
- Reproducible execution (`PYTHONHASHSEED=42`)
- Environment snapshot (packages, versions)
- Mock external APIs in CI
- Export to `build/docs/` (not `../docs`)
- Metadata extraction (execution time, errors)

**File:** `.github/workflows/notebook-execution.yml`

### 5. Comprehensive Validation Runner ‚ú® NEW

**Problem:** Multiple validators needed to be run individually.

**Solution:**
- Single command to run all validations
- Categorized checks (config, security, quality)
- Color-coded output
- Strict mode for CI
- Summary reporting

**File:** `scripts/validate_all.py`

**Usage:**
```bash
# Run all checks
python scripts/validate_all.py

# Strict mode (fail on warnings)
python scripts/validate_all.py --strict

# Specific category
python scripts/validate_all.py --category security

# Quiet mode (summary only)
python scripts/validate_all.py --quiet
```

---

## üé¨ Quick Start

### For New Developers

```bash
# 1. Clone repository
git clone <repo-url>
cd AutoTrader/Autotrader

# 2. Install dependencies
pip install -r requirements.txt
pip install pre-commit

# 3. Set up pre-commit hooks
pre-commit install

# 4. Configure environment
cp .env.example .env
# Edit .env with your API keys (NEVER commit!)

# 5. Validate setup
python scripts/validate_all.py
```

### Daily Workflow

```bash
# Before committing
python scripts/validate_all.py

# Or let pre-commit handle it
git add .
git commit -m "Your message"
# Pre-commit hooks run automatically!

# If pre-commit fails, fix issues and try again
```

---

## üõ†Ô∏è Validation Tools

### 1. Alert Rules Validator

**Purpose:** Validate `configs/alert_rules.yaml` against JSON schema

**Command:**
```bash
python scripts/validate_alert_rules.py --config configs/alert_rules.yaml
```

**Checks:**
- Schema compliance
- Unique rule IDs
- Channel references
- Escalation policy references
- Time unit consistency
- Condition logic

### 2. Prompt Contract Validator

**Purpose:** Validate LLM prompt outputs match expected schemas

**Command:**
```bash
# All prompts
python scripts/validate_prompt_contracts.py

# Specific prompt
python scripts/validate_prompt_contracts.py --prompt narrative_analyzer

# Golden test mode
python scripts/validate_prompt_contracts.py --golden-test
```

**Checks:**
- Schema version present
- No extra keys
- Type correctness
- Enum constraints
- Pattern matching

### 3. Comprehensive Validator

**Purpose:** Run all validation checks at once

**Command:**
```bash
# All checks
python scripts/validate_all.py

# Only security
python scripts/validate_all.py --category security

# Strict mode (fail on warnings)
python scripts/validate_all.py --strict
```

**Categories:**
- `config` - Configuration file validation
- `security` - Semgrep, Bandit
- `secrets` - Secret pattern detection
- `quality` - Ruff, MyPy
- `dependencies` - pip-audit

### 4. Artifact Generator

**Purpose:** Generate artifacts with full provenance tracking

**Command:**
```python
from scripts.generate_artifact import ArtifactGenerator

gen = ArtifactGenerator(...)
metadata = gen.generate_metadata(...)
rendered = gen.render_template(context, metadata)
gen.save_artifact(rendered, metadata)
```

**Features:**
- Jinja2 templating with autoescaping
- CSP headers for HTML
- SHA-256 checksums
- Retention policies
- Classification levels

---

## üîÑ CI/CD Integration

### Security Scan Workflow

**File:** `.github/workflows/security-scan.yml`

**Jobs:**
1. ‚úÖ Semgrep (SAST)
2. ‚úÖ Bandit (Python security)
3. ‚úÖ Dependency Review (PRs only)
4. ‚úÖ pip-audit (vulnerabilities)
5. ‚úÖ Trivy (filesystem + config + container)
6. ‚úÖ Gitleaks (secrets in history)
7. ‚úÖ TruffleHog (verified secrets)
8. ‚úÖ SBOM Generation
9. ‚úÖ License Compliance
10. ‚úÖ **Alert Config Validation** (NEW)
11. ‚úÖ **Prompt Contract Validation** (NEW)

**Triggers:**
- Push to `main`
- Pull requests
- Daily at 6 AM UTC
- Manual dispatch

### Notebook Execution Workflow

**File:** `.github/workflows/notebook-execution.yml`

**Features:**
- Papermill execution with timeout
- Environment snapshot
- Mock external APIs
- HTML conversion
- Metadata extraction
- Artifact upload

**Triggers:**
- Push to `main` (notebooks changed)
- PRs (notebooks changed)
- Weekly on Monday
- Manual dispatch

---

## ü™ù Pre-Commit Hooks

### Installed Hooks

**File:** `.pre-commit-config.yaml`

**Security Hooks:**
- `detect-private-key` - Detect hardcoded keys
- `detect-secrets` - Secret pattern matching
- `bandit` - Python security linting
- `validate-alert-rules` ‚ú® NEW
- `validate-prompt-contracts` ‚ú® NEW
- `validate-llm-config` ‚ú® NEW

**Quality Hooks:**
- `black` - Code formatting
- `ruff` - Linting with auto-fix
- `mypy` - Type checking
- `yamllint` - YAML linting
- `markdownlint` - Markdown linting

**Setup:**
```bash
# Install pre-commit
pip install pre-commit

# Install hooks
pre-commit install

# Run manually
pre-commit run --all-files

# Update hooks
pre-commit autoupdate
```

---

## üìÅ Configuration Files

### Security & Validation

| File | Purpose | Validator |
|------|---------|-----------|
| `configs/alert_rules.yaml` | Alert configuration | `validate_alert_rules.py` |
| `configs/llm_enhanced.yaml` | LLM with cost controls | YAML parser |
| `ci/semgrep.yml` | Custom security rules | Semgrep |
| `.secrets.baseline` | Known non-secrets | detect-secrets |

### Schemas

| File | Purpose |
|------|---------|
| `schemas/artifact_metadata.json` | Artifact metadata structure |
| `schemas/prompt_outputs/narrative_analyzer.json` | Narrative analysis output |
| `schemas/prompt_outputs/contract_safety.json` | Contract safety output |

### Test Fixtures

| File | Purpose |
|------|---------|
| `tests/fixtures/prompt_outputs/narrative_analyzer_golden.json` | Golden test |
| `tests/fixtures/prompt_outputs/contract_safety_golden.json` | Golden test |

---

## üîß Troubleshooting

### Common Issues

#### 1. "Schema validation failed"

**Cause:** Output doesn't match schema

**Solution:**
```bash
# Check schema is valid
cat schemas/prompt_outputs/my_prompt.json | jq .

# Validate manually
python scripts/validate_prompt_contracts.py --prompt my_prompt
```

#### 2. "Timeout in notebook execution"

**Cause:** Notebook takes > 30 minutes

**Solution:**
- Reduce data window
- Mock external API calls
- Increase timeout in workflow (if appropriate)

#### 3. "LLM budget exceeded"

**Cause:** Cost cap reached

**Solution:**
```bash
# Check current spend
curl http://localhost:9090/api/v1/query?query=llm_cost_usd_total

# Adjust in configs/llm_enhanced.yaml
budget:
  daily_usd_cap: 20.00  # Increase if justified
```

#### 4. "Pre-commit hook failing"

**Cause:** Validation errors

**Solution:**
```bash
# Run manually to see details
python scripts/validate_all.py

# Skip hooks temporarily (not recommended)
git commit --no-verify
```

---

## üîÑ Maintenance

### Weekly Tasks

- [ ] Review Dependabot PRs
- [ ] Check security scan results in GitHub Security tab
- [ ] Monitor LLM costs in Prometheus
- [ ] Review artifact retention (delete expired)

### Monthly Tasks

- [ ] Update dependencies (`pip list --outdated`)
- [ ] Review and update Semgrep rules
- [ ] Audit API key usage
- [ ] Check CI/CD performance metrics

### Quarterly Tasks

- [ ] Rotate API keys
- [ ] Security audit (internal or external)
- [ ] Update documentation
- [ ] Review and update schemas

---

## üìö Documentation

### Main Documents

- **`SECURITY_POSTURE_COMPLETE.md`** - Comprehensive security guide (20+ pages)
- **`SECURITY_IMPLEMENTATION_SUMMARY.md`** - Executive summary
- **`SECURITY_QUICK_REF.md`** - Quick reference for developers
- **This file** - Implementation guide

### Additional Resources

- GitHub Security tab - SARIF reports
- Prometheus dashboard - Runtime metrics
- Grafana dashboards - Visualization
- Semgrep rules - `ci/semgrep.yml`

---

## üéì Training

### For Developers

1. **Read:** `SECURITY_POSTURE_COMPLETE.md` (30 min)
2. **Practice:** Run validators locally (15 min)
3. **Try:** Generate an artifact with provenance (30 min)

### For Security Team

1. **Review:** CI/CD workflows (30 min)
2. **Configure:** Prometheus alerts (1 hour)
3. **Audit:** SARIF reports in GitHub Security (ongoing)

---

## üéâ Success Metrics

### Before Implementation

- ‚ùå No prompt schema enforcement
- ‚ùå No LLM cost tracking
- ‚ö†Ô∏è Basic artifact metadata
- ‚ö†Ô∏è Notebook load check only
- ‚úÖ Good CI/CD security (already)

### After Implementation

- ‚úÖ JSON schemas + golden tests
- ‚úÖ LLM cost tracking + budgets + fallbacks
- ‚úÖ Comprehensive artifact provenance
- ‚úÖ Full notebook execution testing
- ‚úÖ Enhanced CI/CD security

**Security Posture:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Enterprise Grade)

---

## üìû Support

**Security Issues:**
- üîí Email: security@crisiscore.systems
- üìù GitHub Security Advisory (private disclosure)

**General Questions:**
- üí¨ GitHub Discussions
- üêõ GitHub Issues (public)
- üìñ Documentation in `docs/`

---

## ‚úÖ Sign-Off

**Implementation Status:** ‚úÖ Complete  
**Testing:** ‚úÖ Passed  
**Documentation:** ‚úÖ Complete  
**Production Ready:** ‚úÖ Yes

**Implemented By:** GitHub Copilot  
**Date:** October 9, 2025  
**Version:** 2.0.0

---

**Next Review Date:** January 9, 2026
