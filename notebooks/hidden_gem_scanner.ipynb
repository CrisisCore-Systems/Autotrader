{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "051fe605",
      "metadata": {},
      "source": [
        "# VoidBloom / CrisisCore Enhanced Prototype Notebook\n",
        "\n",
        "This notebook demonstrates the complete Hidden-Gem Scanner pipeline with:\n",
        "- **Provenance Tracking**: Full lineage tracking of all artifacts and transformations\n",
        "- **Glossary Generation**: Automatic documentation of technical terms and metrics\n",
        "- **Feature Extraction**: Time series analysis and market data processing\n",
        "- **GemScore Calculation**: Weighted scoring with confidence metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dd0fdd1",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be23280c",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Setup comprehensive observability infrastructure for the Hidden Gem Scanner.\n",
        "\n",
        "This includes:\n",
        "1. Structured JSON logging with context binding\n",
        "2. Prometheus metrics for monitoring\n",
        "3. Distributed tracing with OpenTelemetry\n",
        "\"\"\"\n",
        "\n",
        "# Import observability components\n",
        "from src.core.logging_config import init_logging, get_logger, LogContext\n",
        "from src.core.metrics import (\n",
        "    record_scan_request,\n",
        "    record_scan_duration,\n",
        "    record_scan_error,\n",
        "    record_gem_score,\n",
        "    record_confidence_score,\n",
        "    record_flagged_token,\n",
        "    is_prometheus_available,\n",
        ")\n",
        "from src.core.tracing import (\n",
        "    setup_tracing,\n",
        "    trace_operation,\n",
        "    add_span_attributes,\n",
        "    get_trace_id,\n",
        "    is_tracing_available,\n",
        ")\n",
        "\n",
        "# Initialize structured logging\n",
        "logger = init_logging(service_name=\"hidden-gem-scanner\", level=\"INFO\")\n",
        "\n",
        "# Initialize tracing\n",
        "tracer = setup_tracing(service_name=\"hidden-gem-scanner\", enable_console_export=False)\n",
        "\n",
        "# Log initialization\n",
        "logger.info(\n",
        "    \"observability_initialized\",\n",
        "    notebook=\"hidden_gem_scanner\",\n",
        "    prometheus_available=is_prometheus_available(),\n",
        "    tracing_available=is_tracing_available(),\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Observability Stack Initialized\")\n",
        "print(f\"   üìù Structured Logging: Enabled (JSON format)\")\n",
        "print(f\"   üìä Prometheus Metrics: {'Enabled' if is_prometheus_available() else 'Disabled (graceful fallback)'}\")\n",
        "print(f\"   üîç Distributed Tracing: {'Enabled' if is_tracing_available() else 'Disabled (graceful fallback)'}\")\n",
        "print(f\"\\nüìå Trace ID: {get_trace_id() or 'N/A'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from src.core.features import MarketSnapshot\n",
        "from src.core.safety import evaluate_contract, liquidity_guardrail\n",
        "from src.core.provenance_tracking import complete_pipeline_tracked\n",
        "from src.core.provenance import get_provenance_tracker, reset_provenance_tracker\n",
        "from src.core.glossary import get_glossary\n",
        "\n",
        "# Reset tracker for clean demo\n",
        "reset_provenance_tracker()\n",
        "\n",
        "print(\"‚úÖ Imports complete\")\n",
        "print(f\"üìä Provenance tracker ready\")\n",
        "print(f\"üìñ Glossary contains {len(get_glossary().terms)} terms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44deab74",
      "metadata": {},
      "source": [
        "## 0. Initialize Logging & Metrics Infrastructure"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "985b9c6d",
      "metadata": {},
      "source": [
        "## 2. Create Synthetic Market Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09de7bdb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create synthetic price series showing uptrend\n",
        "from datetime import datetime, timezone, timedelta\n",
        "\n",
        "# Use fixed date for reproducibility\n",
        "now = datetime(2025, 10, 9, 12, 0, 0, tzinfo=timezone.utc)\n",
        "dates = [now - timedelta(hours=i) for i in range(48)][::-1]\n",
        "prices = pd.Series(\n",
        "    data=[0.03 + 0.0002 * i for i in range(48)],\n",
        "    index=pd.to_datetime(dates)\n",
        ")\n",
        "\n",
        "# Log data generation with structured context\n",
        "with LogContext(logger, operation=\"data_generation\", token=\"VBLOOM\") as log:\n",
        "    log.info(\n",
        "        \"synthetic_data_created\",\n",
        "        price_points=len(prices),\n",
        "        start_price=prices.iloc[0],\n",
        "        end_price=prices.iloc[-1],\n",
        "        time_range_hours=48,\n",
        "    )\n",
        "\n",
        "# Create market snapshot\n",
        "snapshot = MarketSnapshot(\n",
        "    symbol=\"VBLOOM\",\n",
        "    timestamp=now,\n",
        "    price=float(prices.iloc[-1]),\n",
        "    volume_24h=250000,\n",
        "    liquidity_usd=180000,\n",
        "    holders=4200,\n",
        "    onchain_metrics={\"active_wallets\": 950, \"net_inflows\": 125000, \"unlock_pressure\": 0.2},\n",
        "    narratives=[\"AI\", \"DeFi\", \"VoidBloom\"]\n",
        ")\n",
        "\n",
        "# Create contract safety report\n",
        "contract_report = evaluate_contract(\n",
        "    {\"honeypot\": False, \"owner_can_mint\": False, \"owner_can_withdraw\": False, \"unverified\": False},\n",
        "    severity=\"none\"\n",
        ")\n",
        "\n",
        "# Log snapshot creation with metrics\n",
        "logger.info(\n",
        "    \"market_snapshot_created\",\n",
        "    symbol=snapshot.symbol,\n",
        "    price=snapshot.price,\n",
        "    volume_24h=snapshot.volume_24h,\n",
        "    liquidity_usd=snapshot.liquidity_usd,\n",
        "    holders=snapshot.holders,\n",
        "    contract_safety_score=contract_report.score,\n",
        ")\n",
        "\n",
        "print(f\"üìà Generated {len(prices)} price points for {snapshot.symbol}\")\n",
        "print(f\"üí∞ Current price: ${snapshot.price:.6f}\")\n",
        "print(f\"üíß Liquidity: ${snapshot.liquidity_usd:,.0f}\")\n",
        "print(f\"üë• Holders: {snapshot.holders:,}\")\n",
        "print(f\"üõ°Ô∏è Contract safety score: {contract_report.score:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b05f6926",
      "metadata": {},
      "source": [
        "## 3. Execute Pipeline with Provenance Tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "621912c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute complete pipeline with provenance tracking, logging, and metrics\n",
        "import time\n",
        "\n",
        "# Start timing for metrics\n",
        "start_time = time.time()\n",
        "token_symbol = snapshot.symbol\n",
        "\n",
        "# Log pipeline execution start\n",
        "logger.info(\n",
        "    \"pipeline_execution_started\",\n",
        "    token=token_symbol,\n",
        "    data_source=\"synthetic_demo\",\n",
        "    trace_id=get_trace_id(),\n",
        ")\n",
        "\n",
        "try:\n",
        "    # Execute with distributed tracing\n",
        "    with trace_operation(\"complete_pipeline\", attributes={\"token\": token_symbol, \"source\": \"synthetic_demo\"}):\n",
        "        results = complete_pipeline_tracked(\n",
        "            snapshot=snapshot,\n",
        "            price_series=prices,\n",
        "            narrative_embedding_score=0.72,\n",
        "            contract_report=contract_report,\n",
        "            data_source=\"synthetic_demo\"\n",
        "        )\n",
        "        \n",
        "        # Calculate duration\n",
        "        duration_seconds = time.time() - start_time\n",
        "        \n",
        "        # Record metrics\n",
        "        record_scan_request(token_symbol, \"success\")\n",
        "        record_scan_duration(token_symbol, duration_seconds, \"success\")\n",
        "        record_gem_score(token_symbol, results['result'].score)\n",
        "        record_confidence_score(token_symbol, results['result'].confidence / 100)\n",
        "        \n",
        "        if results['flagged']:\n",
        "            record_flagged_token(token_symbol, \"manual_review_required\")\n",
        "        \n",
        "        # Log successful completion with full context\n",
        "        logger.info(\n",
        "            \"pipeline_execution_completed\",\n",
        "            token=token_symbol,\n",
        "            gem_score=results['result'].score,\n",
        "            confidence=results['result'].confidence,\n",
        "            flagged=results['flagged'],\n",
        "            duration_seconds=duration_seconds,\n",
        "            top_features=[k for k, v in sorted(results['result'].contributions.items(), key=lambda x: -x[1])[:3]],\n",
        "            trace_id=get_trace_id(),\n",
        "        )\n",
        "        \n",
        "except Exception as e:\n",
        "    # Record error metrics\n",
        "    duration_seconds = time.time() - start_time\n",
        "    record_scan_request(token_symbol, \"failure\")\n",
        "    record_scan_duration(token_symbol, duration_seconds, \"failure\")\n",
        "    record_scan_error(token_symbol, type(e).__name__)\n",
        "    \n",
        "    # Log error with full context\n",
        "    logger.error(\n",
        "        \"pipeline_execution_failed\",\n",
        "        token=token_symbol,\n",
        "        error_type=type(e).__name__,\n",
        "        error_message=str(e),\n",
        "        duration_seconds=duration_seconds,\n",
        "        trace_id=get_trace_id(),\n",
        "    )\n",
        "    raise\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üìä ANALYSIS RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nüíé GemScore: {results['result'].score:.2f}\")\n",
        "print(f\"üéØ Confidence: {results['result'].confidence:.2f}%\")\n",
        "print(f\"üö© Flagged for Review: {results['flagged']}\")\n",
        "print(f\"‚è±Ô∏è  Duration: {duration_seconds:.3f}s\")\n",
        "print(f\"üîç Trace ID: {get_trace_id() or 'N/A'}\")\n",
        "print(f\"\\nüìã Feature Contributions:\")\n",
        "for feature, contribution in sorted(results['result'].contributions.items(), key=lambda x: -x[1]):\n",
        "    print(f\"  - {feature}: {contribution:.4f}\")\n",
        "\n",
        "print(f\"\\nüîç Debug Info:\")\n",
        "for key, value in results['debug'].items():\n",
        "    print(f\"  - {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47257eef",
      "metadata": {},
      "source": [
        "## 4. Explore Artifact Provenance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ff32a56",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get provenance information\n",
        "tracker = get_provenance_tracker()\n",
        "score_id = results['provenance']['score_id']\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üîç ARTIFACT PROVENANCE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Get the score record\n",
        "score_record = tracker.get_record(score_id)\n",
        "if score_record:\n",
        "    print(f\"\\nüì¶ Artifact: {score_record.artifact.name}\")\n",
        "    print(f\"üÜî ID: {score_id[:16]}...\")\n",
        "    print(f\"üìÖ Created: {score_record.artifact.created_at.strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
        "    print(f\"üè∑Ô∏è Tags: {', '.join(score_record.artifact.tags)}\")\n",
        "    \n",
        "    print(f\"\\nüîÑ Transformations Applied:\")\n",
        "    for i, transform in enumerate(score_record.transformations, 1):\n",
        "        print(f\"  {i}. {transform.function_name} ({transform.transformation_type.value})\")\n",
        "        print(f\"     ‚è±Ô∏è Duration: {transform.duration_ms:.2f}ms\")\n",
        "    \n",
        "    print(f\"\\nüìä Quality Metrics:\")\n",
        "    for metric, value in list(score_record.quality_metrics.items())[:5]:\n",
        "        print(f\"  - {metric}: {value:.4f}\")\n",
        "    \n",
        "    if score_record.annotations:\n",
        "        print(f\"\\nüí¨ Annotations:\")\n",
        "        for annotation in score_record.annotations:\n",
        "            print(f\"  - {annotation}\")\n",
        "\n",
        "# Get complete lineage\n",
        "lineage = tracker.get_lineage(score_id)\n",
        "print(f\"\\nüå≥ Lineage Depth: {len(lineage)} artifacts\")\n",
        "print(f\"üìà Artifact chain:\")\n",
        "for i, artifact_id in enumerate(lineage):\n",
        "    record = tracker.get_record(artifact_id)\n",
        "    if record:\n",
        "        print(f\"  {i+1}. {record.artifact.artifact_type.value}: {record.artifact.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75102dea",
      "metadata": {},
      "source": [
        "## 5. Visualize Lineage Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9a13264",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export lineage as Mermaid diagram\n",
        "mermaid_diagram = tracker.export_lineage_graph(score_id, format=\"mermaid\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üé® LINEAGE DIAGRAM (Mermaid)\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nCopy this to https://mermaid.live for visualization:\\n\")\n",
        "print(mermaid_diagram)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# Get tracker statistics\n",
        "stats = tracker.get_statistics()\n",
        "print(\"\\nüìä PROVENANCE STATISTICS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Total Artifacts: {stats['total_artifacts']}\")\n",
        "print(f\"Total Transformations: {stats['total_transformations']}\")\n",
        "print(f\"Lineage Edges: {stats['lineage_edges']}\")\n",
        "print(f\"\\nArtifacts by Type:\")\n",
        "for artifact_type, count in stats['artifacts_by_type'].items():\n",
        "    print(f\"  - {artifact_type}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a8d6c65",
      "metadata": {},
      "source": [
        "## 6. Explore Technical Glossary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf41a49c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explore the glossary\n",
        "glossary = get_glossary()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üìñ TECHNICAL GLOSSARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Get glossary statistics\n",
        "glossary_stats = glossary.get_statistics()\n",
        "print(f\"\\nTotal Terms: {glossary_stats['total_terms']}\")\n",
        "print(f\"Categories: {glossary_stats['categories_count']}\")\n",
        "print(f\"\\nTerms by Category:\")\n",
        "for category, count in glossary_stats['category_breakdown'].items():\n",
        "    print(f\"  - {category}: {count}\")\n",
        "\n",
        "# Show some key terms\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üìö SAMPLE TERMS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "key_terms = [\"GemScore\", \"RSI\", \"ContractSafety\", \"Confidence\"]\n",
        "for term_name in key_terms:\n",
        "    term = glossary.get_term(term_name)\n",
        "    if term:\n",
        "        print(f\"\\n{term.term}\")\n",
        "        print(\"-\" * 40)\n",
        "        print(f\"Category: {term.category.value}\")\n",
        "        print(f\"Definition: {term.definition}\")\n",
        "        if term.formula:\n",
        "            print(f\"Formula: {term.formula}\")\n",
        "        if term.range:\n",
        "            print(f\"Range: [{term.range[0]}, {term.range[1]}]\")\n",
        "        if term.related_terms:\n",
        "            print(f\"Related: {', '.join(list(term.related_terms)[:3])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ec7c2e8",
      "metadata": {},
      "source": [
        "## 7. Search Glossary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59918c1a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Search for terms related to risk\n",
        "search_results = glossary.search(\"risk\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üîç SEARCH RESULTS: 'risk'\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for term in search_results:\n",
        "    print(f\"\\n‚úì {term.term} ({term.category.value})\")\n",
        "    print(f\"  {term.definition[:100]}...\")\n",
        "\n",
        "# Get all terms in a specific category\n",
        "from src.core.glossary import TermCategory\n",
        "\n",
        "risk_factors = glossary.get_by_category(TermCategory.RISK_FACTOR)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"‚ö†Ô∏è ALL RISK FACTORS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for term in risk_factors:\n",
        "    print(f\"\\n‚Ä¢ {term.term}\")\n",
        "    print(f\"  {term.definition}\")\n",
        "    if term.range:\n",
        "        print(f\"  Range: [{term.range[0]}, {term.range[1]}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e83e5080",
      "metadata": {},
      "source": [
        "## 8. Export Documentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c29ecf8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Export glossary as markdown\n",
        "# Use path relative to notebook location\n",
        "notebook_dir = Path.cwd()\n",
        "if notebook_dir.name == \"notebooks\":\n",
        "    docs_dir = notebook_dir.parent / \"docs\"\n",
        "else:\n",
        "    docs_dir = notebook_dir / \"docs\"\n",
        "\n",
        "docs_dir.mkdir(exist_ok=True)\n",
        "\n",
        "glossary_path = docs_dir / \"GLOSSARY.md\"\n",
        "glossary_markdown = glossary.export_markdown(output_path=glossary_path, include_toc=True, group_by_category=True)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üìÑ EXPORTED DOCUMENTATION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\n‚úÖ Glossary exported to: {glossary_path}\")\n",
        "print(f\"üìè Document size: {len(glossary_markdown)} characters\")\n",
        "\n",
        "# Export as JSON for programmatic access\n",
        "glossary_json_path = docs_dir / \"glossary.json\"\n",
        "glossary_json = glossary.export_json(output_path=glossary_json_path)\n",
        "\n",
        "print(f\"‚úÖ JSON export to: {glossary_json_path}\")\n",
        "\n",
        "# Show preview of markdown\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üìÑ GLOSSARY PREVIEW (first 500 chars)\")\n",
        "print(\"=\" * 60)\n",
        "print(glossary_markdown[:500] + \"...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f053c7e6",
      "metadata": {},
      "source": [
        "## 9. Extended Backtest Metrics (IC & Risk-Adjusted Performance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "244de76c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from backtest.extended_metrics import (\n",
        "    calculate_extended_metrics,\n",
        "    calculate_ic_metrics,\n",
        "    format_ic_summary,\n",
        ")\n",
        "\n",
        "# IMPORTANT: Set seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Create synthetic backtest data\n",
        "# Simulate 50 token snapshots with predictions and actual returns\n",
        "\n",
        "# Generate predictions (GemScores)\n",
        "predictions = np.random.uniform(0.3, 0.9, 50)\n",
        "\n",
        "# Generate actual returns with some correlation to predictions\n",
        "actual_returns = predictions * 0.05 + np.random.normal(0, 0.02, 50)\n",
        "\n",
        "# Create mock snapshots\n",
        "class MockSnapshot:\n",
        "    def __init__(self, token, features, future_return):\n",
        "        self.token = token\n",
        "        self.features = features\n",
        "        self.future_return_7d = future_return\n",
        "\n",
        "snapshots = [\n",
        "    MockSnapshot(f\"TOKEN{i:02d}\", {}, actual_returns[i])\n",
        "    for i in range(50)\n",
        "]\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üìä SYNTHETIC BACKTEST DATA (SEED=42)\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Total Snapshots: {len(snapshots)}\")\n",
        "print(f\"Prediction Range: [{predictions.min():.4f}, {predictions.max():.4f}]\")\n",
        "print(f\"Return Range: [{actual_returns.min():.4f}, {actual_returns.max():.4f}]\")\n",
        "print(f\"Mean Return: {actual_returns.mean():.4f}\")\n",
        "print(f\"Return Std Dev: {actual_returns.std():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c97588e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate Information Coefficient (IC) metrics\n",
        "ic_metrics = calculate_ic_metrics(predictions, actual_returns)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üìà INFORMATION COEFFICIENT ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "print(format_ic_summary(ic_metrics))\n",
        "\n",
        "# Interpretation\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üîç IC INTERPRETATION\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "The Information Coefficient measures the correlation between predicted\n",
        "scores and actual returns. Key insights:\n",
        "\n",
        "1. **Pearson IC**: Measures linear correlation\n",
        "   - IC > 0.05: Strong predictive power\n",
        "   - IC > 0.02: Moderate predictive power\n",
        "   - IC < 0.02: Weak predictive power\n",
        "\n",
        "2. **Spearman IC**: Measures rank correlation (robust to outliers)\n",
        "   - Useful when returns are skewed or have outliers\n",
        "\n",
        "3. **Kendall's Tau**: Alternative rank correlation\n",
        "   - More conservative than Spearman\n",
        "\n",
        "4. **Hit Rate**: Percentage of correct direction predictions\n",
        "   - > 55%: Better than random for direction\n",
        "   - > 60%: Strong directional signal\n",
        "\n",
        "5. **IC IR (Information Ratio)**: IC_mean / IC_std\n",
        "   - Measures consistency of IC across periods\n",
        "   - Higher is better (more stable predictions)\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0eb5e30",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate comprehensive extended metrics\n",
        "extended_metrics = calculate_extended_metrics(\n",
        "    snapshots=snapshots,\n",
        "    predictions=predictions,\n",
        "    top_k=10,  # Evaluate top 10 predictions\n",
        "    risk_free_rate=0.0,\n",
        "    periods_per_year=52,  # Weekly returns\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üí∞ COMPREHENSIVE BACKTEST METRICS\")\n",
        "print(\"=\" * 70)\n",
        "print(extended_metrics.summary_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cf94d87",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare with baseline strategies\n",
        "from backtest.baseline_strategies import (\n",
        "    RandomStrategy,\n",
        "    CapWeightedStrategy,\n",
        "    SimpleMomentumStrategy,\n",
        ")\n",
        "from backtest.extended_metrics import compare_extended_metrics\n",
        "\n",
        "# Add market cap and momentum features to snapshots for baseline comparison\n",
        "for i, snap in enumerate(snapshots):\n",
        "    snap.features = {\n",
        "        'MarketCap': np.random.uniform(100000, 10000000),\n",
        "        'PriceChange7d': np.random.uniform(-0.1, 0.2),\n",
        "    }\n",
        "\n",
        "# Calculate baseline metrics\n",
        "baseline_strategies = [\n",
        "    RandomStrategy(),\n",
        "    CapWeightedStrategy(),\n",
        "    SimpleMomentumStrategy(),\n",
        "]\n",
        "\n",
        "baseline_metrics = {}\n",
        "for strategy in baseline_strategies:\n",
        "    # Select assets using baseline strategy\n",
        "    selected = strategy.select_assets(snapshots, top_k=10, seed=42)\n",
        "    \n",
        "    # Get predictions (uniform for baselines)\n",
        "    baseline_predictions = np.array([1.0 if snap in selected else 0.0 for snap in snapshots])\n",
        "    \n",
        "    # Calculate metrics\n",
        "    baseline_metrics[strategy.get_name()] = calculate_extended_metrics(\n",
        "        snapshots=snapshots,\n",
        "        predictions=baseline_predictions,\n",
        "        top_k=10,\n",
        "        risk_free_rate=0.0,\n",
        "        periods_per_year=52,\n",
        "    )\n",
        "\n",
        "# Compare GemScore to baselines\n",
        "comparisons = compare_extended_metrics(extended_metrics, baseline_metrics)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üéØ BASELINE COMPARISONS\")\n",
        "print(\"=\" * 70)\n",
        "for baseline_name, comparison in comparisons.items():\n",
        "    print(f\"\\n{baseline_name.replace('_', ' ').title()}:\")\n",
        "    print(f\"  IC Improvement:     {comparison['ic_improvement']:>8.4f}  {'‚úÖ' if comparison['ic_better'] else '‚ùå'}\")\n",
        "    print(f\"  Sharpe Improvement: {comparison['sharpe_improvement']:>8.4f}  {'‚úÖ' if comparison['sharpe_better'] else '‚ùå'}\")\n",
        "    print(f\"  Sortino Improvement:{comparison['sortino_improvement']:>8.4f}\")\n",
        "    print(f\"  Return Improvement: {comparison['return_improvement']:>8.4f}\")\n",
        "    print(f\"  Risk-Adjusted Better: {'‚úÖ YES' if comparison['risk_adjusted_better'] else '‚ùå NO'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "796f2cc0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize IC distribution over multiple periods\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Simulate multi-period IC\n",
        "np.random.seed(42)\n",
        "n_periods = 20\n",
        "period_ics = []\n",
        "\n",
        "for period in range(n_periods):\n",
        "    # Generate predictions and actuals for each period\n",
        "    period_preds = np.random.uniform(0.3, 0.9, 30)\n",
        "    period_actuals = period_preds * 0.05 + np.random.normal(0, 0.025, 30)\n",
        "    \n",
        "    # Calculate IC for this period\n",
        "    from scipy import stats\n",
        "    ic, _ = stats.pearsonr(period_preds, period_actuals)\n",
        "    period_ics.append(ic)\n",
        "\n",
        "# Create visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# IC over time\n",
        "axes[0, 0].plot(range(1, n_periods + 1), period_ics, marker='o', linewidth=2)\n",
        "axes[0, 0].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
        "axes[0, 0].axhline(y=0.02, color='orange', linestyle='--', alpha=0.5, label='Moderate IC')\n",
        "axes[0, 0].axhline(y=0.05, color='green', linestyle='--', alpha=0.5, label='Strong IC')\n",
        "axes[0, 0].set_xlabel('Period')\n",
        "axes[0, 0].set_ylabel('Information Coefficient')\n",
        "axes[0, 0].set_title('IC Over Time')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# IC distribution\n",
        "axes[0, 1].hist(period_ics, bins=15, edgecolor='black', alpha=0.7)\n",
        "axes[0, 1].axvline(x=np.mean(period_ics), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(period_ics):.4f}')\n",
        "axes[0, 1].set_xlabel('Information Coefficient')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "axes[0, 1].set_title('IC Distribution')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# Predictions vs Actuals scatter\n",
        "axes[1, 0].scatter(predictions[:30], actual_returns[:30], alpha=0.6)\n",
        "axes[1, 0].plot([predictions.min(), predictions.max()], \n",
        "                [predictions.min() * 0.05, predictions.max() * 0.05], \n",
        "                'r--', label='Expected Relationship')\n",
        "axes[1, 0].set_xlabel('Predicted Score')\n",
        "axes[1, 0].set_ylabel('Actual Return')\n",
        "axes[1, 0].set_title('Predictions vs Actual Returns')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "# Cumulative returns\n",
        "cumulative_returns = np.cumsum(actual_returns[:30])\n",
        "axes[1, 1].plot(range(1, 31), cumulative_returns, linewidth=2)\n",
        "axes[1, 1].fill_between(range(1, 31), 0, cumulative_returns, alpha=0.3)\n",
        "axes[1, 1].set_xlabel('Asset Index (sorted by GemScore)')\n",
        "axes[1, 1].set_ylabel('Cumulative Return')\n",
        "axes[1, 1].set_title('Cumulative Returns (Top 30)')\n",
        "axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../docs/ic_analysis.png', dpi=150, bbox_inches='tight')\n",
        "print(\"üìä Visualization saved to: ../docs/ic_analysis.png\")\n",
        "plt.show()\n",
        "\n",
        "# Print IC statistics\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üìä IC STATISTICS (Multi-Period)\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Mean IC:        {np.mean(period_ics):>8.4f}\")\n",
        "print(f\"Median IC:      {np.median(period_ics):>8.4f}\")\n",
        "print(f\"Std Dev IC:     {np.std(period_ics):>8.4f}\")\n",
        "print(f\"IC IR:          {np.mean(period_ics) / np.std(period_ics):>8.4f}\")\n",
        "print(f\"Min IC:         {np.min(period_ics):>8.4f}\")\n",
        "print(f\"Max IC:         {np.max(period_ics):>8.4f}\")\n",
        "print(f\"Positive ICs:   {sum(ic > 0 for ic in period_ics)}/{n_periods} ({100 * sum(ic > 0 for ic in period_ics) / n_periods:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4daa4703",
      "metadata": {},
      "source": [
        "## üìä Observability Dashboard: View Metrics & Logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40b99f9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Observability Dashboard: View collected metrics and logs.\n",
        "\n",
        "This cell demonstrates:\n",
        "1. Viewing Prometheus metrics programmatically\n",
        "2. Accessing structured logs\n",
        "3. Checking trace information\n",
        "4. System health overview\n",
        "\"\"\"\n",
        "\n",
        "from prometheus_client import REGISTRY, generate_latest\n",
        "import json\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"üìä PROMETHEUS METRICS DASHBOARD\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if is_prometheus_available():\n",
        "    # Get all metrics\n",
        "    metrics_output = generate_latest(REGISTRY).decode('utf-8')\n",
        "    \n",
        "    # Parse and display scanner-specific metrics\n",
        "    scanner_metrics = [\n",
        "        line for line in metrics_output.split('\\n')\n",
        "        if any(keyword in line for keyword in ['scan_', 'gem_score', 'confidence_score', 'flagged_tokens'])\n",
        "        and not line.startswith('#')\n",
        "        and line.strip()\n",
        "    ]\n",
        "    \n",
        "    print(\"\\nüîç Scanner Metrics:\\n\")\n",
        "    for metric in scanner_metrics[:20]:  # Show first 20\n",
        "        print(f\"  {metric}\")\n",
        "    \n",
        "    if len(scanner_metrics) > 20:\n",
        "        print(f\"\\n  ... and {len(scanner_metrics) - 20} more metrics\")\n",
        "    \n",
        "    # Count metrics by type\n",
        "    scan_requests = len([m for m in scanner_metrics if 'scan_requests_total' in m])\n",
        "    gem_scores = len([m for m in scanner_metrics if 'gem_score_distribution' in m])\n",
        "    \n",
        "    print(f\"\\nüìà Metrics Summary:\")\n",
        "    print(f\"  - Scan requests tracked: {scan_requests}\")\n",
        "    print(f\"  - GemScore distributions: {gem_scores}\")\n",
        "    \n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  Prometheus client not available - metrics are mocked\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìù STRUCTURED LOGGING STATUS\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n‚úÖ Logging Format: JSON\")\n",
        "print(f\"‚úÖ Service Name: hidden-gem-scanner\")\n",
        "print(f\"‚úÖ Context Binding: Enabled\")\n",
        "print(f\"‚úÖ Trace Correlation: {get_trace_id() or 'N/A'}\")\n",
        "\n",
        "print(\"\\nüí° To view all logs in JSON format:\")\n",
        "print(\"   - Logs are written to stdout/stderr\")\n",
        "print(\"   - Each log entry is a valid JSON object\")\n",
        "print(\"   - Can be piped to jq for parsing: python script.py 2>&1 | jq .\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üîç DISTRIBUTED TRACING\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if is_tracing_available():\n",
        "    print(f\"\\n‚úÖ Tracing: Enabled\")\n",
        "    print(f\"‚úÖ Current Trace ID: {get_trace_id() or 'N/A'}\")\n",
        "    print(f\"‚úÖ Service: hidden-gem-scanner\")\n",
        "    print(\"\\nüí° Traces can be exported to:\")\n",
        "    print(\"   - Jaeger (set JAEGER_ENDPOINT)\")\n",
        "    print(\"   - Zipkin\")\n",
        "    print(\"   - OTLP-compatible backends\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è  Tracing: Disabled (graceful fallback)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üéØ OBSERVABILITY QUICK ACTIONS\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\"\"\n",
        "1. Start Metrics Server:\n",
        "   python -m src.services.metrics_server --port 9090\n",
        "\n",
        "2. View Metrics Endpoint:\n",
        "   curl http://localhost:9090/metrics\n",
        "\n",
        "3. Query with Prometheus:\n",
        "   - Install Prometheus: https://prometheus.io/download/\n",
        "   - Configure scrape target: localhost:9090\n",
        "   - Query: rate(scan_requests_total[5m])\n",
        "\n",
        "4. View Logs with jq:\n",
        "   python your_script.py 2>&1 | jq 'select(.event==\"scan_completed\")'\n",
        "\n",
        "5. Monitor in Real-Time:\n",
        "   watch -n 1 'curl -s http://localhost:9090/metrics | grep scan_requests'\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bc9f228",
      "metadata": {},
      "source": [
        "## üöÄ Production Monitoring Patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10e851b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Production-Ready Monitoring Patterns\n",
        "\n",
        "Demonstrates:\n",
        "1. Error handling with metrics\n",
        "2. Performance monitoring\n",
        "3. Alert-worthy conditions\n",
        "4. Batch processing with metrics\n",
        "\"\"\"\n",
        "\n",
        "from contextlib import contextmanager\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "@contextmanager\n",
        "def monitored_operation(operation_name: str, token: str):\n",
        "    \"\"\"Context manager for monitored operations with automatic logging and metrics.\"\"\"\n",
        "    start = time.time()\n",
        "    operation_logger = logger.bind(operation=operation_name, token=token)\n",
        "    \n",
        "    operation_logger.info(f\"{operation_name}_started\")\n",
        "    \n",
        "    try:\n",
        "        yield operation_logger\n",
        "        duration = time.time() - start\n",
        "        \n",
        "        # Log success\n",
        "        operation_logger.info(\n",
        "            f\"{operation_name}_completed\",\n",
        "            duration_seconds=duration,\n",
        "            status=\"success\"\n",
        "        )\n",
        "        \n",
        "    except Exception as e:\n",
        "        duration = time.time() - start\n",
        "        \n",
        "        # Log and record error\n",
        "        operation_logger.error(\n",
        "            f\"{operation_name}_failed\",\n",
        "            duration_seconds=duration,\n",
        "            error_type=type(e).__name__,\n",
        "            error_message=str(e),\n",
        "            status=\"failure\"\n",
        "        )\n",
        "        \n",
        "        # Record error metric\n",
        "        record_scan_error(token, type(e).__name__)\n",
        "        raise\n",
        "\n",
        "\n",
        "# Example: Batch processing with monitoring\n",
        "def process_token_batch(tokens: List[str]) -> Dict[str, Any]:\n",
        "    \"\"\"Process a batch of tokens with comprehensive monitoring.\"\"\"\n",
        "    \n",
        "    results = {}\n",
        "    batch_start = time.time()\n",
        "    \n",
        "    logger.info(\n",
        "        \"batch_processing_started\",\n",
        "        batch_size=len(tokens),\n",
        "        tokens=tokens[:5] if len(tokens) > 5 else tokens,\n",
        "    )\n",
        "    \n",
        "    success_count = 0\n",
        "    error_count = 0\n",
        "    \n",
        "    for token in tokens:\n",
        "        try:\n",
        "            with monitored_operation(\"token_scan\", token):\n",
        "                # Simulate token processing\n",
        "                scan_start = time.time()\n",
        "                \n",
        "                # Mock scan (replace with actual scan logic)\n",
        "                mock_score = 75.0 + (hash(token) % 20)\n",
        "                mock_confidence = 0.8 + (hash(token) % 20) / 100\n",
        "                \n",
        "                scan_duration = time.time() - scan_start\n",
        "                \n",
        "                # Record metrics\n",
        "                record_scan_request(token, \"success\")\n",
        "                record_scan_duration(token, scan_duration, \"success\")\n",
        "                record_gem_score(token, mock_score)\n",
        "                record_confidence_score(token, mock_confidence)\n",
        "                \n",
        "                results[token] = {\n",
        "                    \"score\": mock_score,\n",
        "                    \"confidence\": mock_confidence,\n",
        "                    \"status\": \"success\"\n",
        "                }\n",
        "                \n",
        "                success_count += 1\n",
        "                \n",
        "        except Exception as e:\n",
        "            error_count += 1\n",
        "            results[token] = {\n",
        "                \"error\": str(e),\n",
        "                \"status\": \"error\"\n",
        "            }\n",
        "    \n",
        "    batch_duration = time.time() - batch_start\n",
        "    \n",
        "    # Log batch completion with summary\n",
        "    logger.info(\n",
        "        \"batch_processing_completed\",\n",
        "        batch_size=len(tokens),\n",
        "        success_count=success_count,\n",
        "        error_count=error_count,\n",
        "        batch_duration_seconds=batch_duration,\n",
        "        avg_duration_per_token=batch_duration / len(tokens),\n",
        "        success_rate=success_count / len(tokens),\n",
        "    )\n",
        "    \n",
        "    return results\n",
        "\n",
        "\n",
        "# Demo: Process sample batch\n",
        "sample_tokens = [\"TOKEN1\", \"TOKEN2\", \"TOKEN3\", \"ERROR_TOKEN\", \"TOKEN5\"]\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"üîÑ BATCH PROCESSING WITH MONITORING\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Simulate an error for ERROR_TOKEN\n",
        "def simulate_scan(token):\n",
        "    if token == \"ERROR_TOKEN\":\n",
        "        raise ValueError(\"Simulated error for demonstration\")\n",
        "    return True\n",
        "\n",
        "# Patch for demo\n",
        "original_process = process_token_batch\n",
        "\n",
        "batch_results = process_token_batch(sample_tokens)\n",
        "\n",
        "print(f\"\\n‚úÖ Batch completed:\")\n",
        "print(f\"   Total: {len(sample_tokens)} tokens\")\n",
        "print(f\"   Success: {sum(1 for r in batch_results.values() if r['status'] == 'success')}\")\n",
        "print(f\"   Errors: {sum(1 for r in batch_results.values() if r['status'] == 'error')}\")\n",
        "\n",
        "print(\"\\nüìä Results:\")\n",
        "for token, result in batch_results.items():\n",
        "    if result['status'] == 'success':\n",
        "        print(f\"   ‚úì {token}: Score={result['score']:.1f}, Confidence={result['confidence']:.2f}\")\n",
        "    else:\n",
        "        print(f\"   ‚úó {token}: {result.get('error', 'Unknown error')}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üéØ PRODUCTION MONITORING CHECKLIST\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\"\"\n",
        "‚úÖ Structured Logging\n",
        "   - All events logged with context\n",
        "   - Errors include stack traces\n",
        "   - JSON format for log aggregation\n",
        "\n",
        "‚úÖ Metrics Collection\n",
        "   - Request counts per token\n",
        "   - Latency histograms\n",
        "   - Error rates by type\n",
        "   - Score distributions\n",
        "\n",
        "‚úÖ Distributed Tracing\n",
        "   - Trace IDs for correlation\n",
        "   - Span attributes for context\n",
        "   - Cross-service tracing ready\n",
        "\n",
        "‚úÖ Error Handling\n",
        "   - Graceful degradation\n",
        "   - Error metrics recorded\n",
        "   - Detailed error logging\n",
        "\n",
        "‚úÖ Performance Tracking\n",
        "   - Operation timing\n",
        "   - Batch processing metrics\n",
        "   - Resource utilization\n",
        "\n",
        "üìã Next Steps for Production:\n",
        "   1. Set up Prometheus server\n",
        "   2. Configure Grafana dashboards\n",
        "   3. Set up alerting rules\n",
        "   4. Configure log aggregation (ELK/Datadog)\n",
        "   5. Enable Jaeger for distributed tracing\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cef9bfa",
      "metadata": {},
      "source": [
        "## üö® Alert Engine v2 - Compound Logic & Suppression\n",
        "\n",
        "Advanced alerting with:\n",
        "- **Compound conditions** (AND/OR/NOT logic)\n",
        "- **Alert suppression** (prevent alert fatigue)\n",
        "- **Deduplication** (fingerprint-based)\n",
        "- **Escalation policies** (tiered notifications)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a836109",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Alert Engine v2\n",
        "from src.services.alerting_v2 import (\n",
        "    AlertCondition, CompoundCondition, AlertRule, AlertManager,\n",
        "    SuppressionRule, EscalationPolicy, Alert\n",
        ")\n",
        "from datetime import timedelta\n",
        "\n",
        "# Create alert manager\n",
        "alert_manager = AlertManager()\n",
        "\n",
        "# Example 1: Simple condition alert\n",
        "simple_condition = AlertCondition(\n",
        "    metric=\"gem_score\",\n",
        "    operator=\"lt\",\n",
        "    threshold=30\n",
        ")\n",
        "\n",
        "simple_rule = AlertRule(\n",
        "    id=\"low_score_warning\",\n",
        "    name=\"Low GemScore Warning\",\n",
        "    condition=simple_condition,\n",
        "    severity=\"warning\",\n",
        "    message=\"Token has low GemScore: {gem_score}\"\n",
        ")\n",
        "\n",
        "alert_manager.add_rule(simple_rule)\n",
        "\n",
        "# Example 2: Compound AND condition - Critical risk\n",
        "critical_condition = CompoundCondition(\n",
        "    operator=\"AND\",\n",
        "    conditions=[\n",
        "        AlertCondition(\"gem_score\", \"lt\", 30),\n",
        "        AlertCondition(\"honeypot_detected\", \"eq\", True)\n",
        "    ]\n",
        ")\n",
        "\n",
        "critical_rule = AlertRule(\n",
        "    id=\"critical_risk\",\n",
        "    name=\"Critical Risk Detected\",\n",
        "    condition=critical_condition,\n",
        "    severity=\"critical\",\n",
        "    message=\"CRITICAL: Low score AND honeypot detected!\"\n",
        ")\n",
        "\n",
        "alert_manager.add_rule(critical_rule)\n",
        "\n",
        "# Example 3: Complex nested condition\n",
        "suspicious_condition = CompoundCondition(\n",
        "    operator=\"AND\",\n",
        "    conditions=[\n",
        "        AlertCondition(\"gem_score\", \"gte\", 70),\n",
        "        CompoundCondition(\n",
        "            operator=\"OR\",\n",
        "            conditions=[\n",
        "                AlertCondition(\"liquidity_usd\", \"lt\", 10000),\n",
        "                AlertCondition(\"safety_score\", \"lt\", 0.5)\n",
        "            ]\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "suspicious_rule = AlertRule(\n",
        "    id=\"suspicious_high_score\",\n",
        "    name=\"Suspicious High Score\",\n",
        "    condition=suspicious_condition,\n",
        "    severity=\"warning\",\n",
        "    message=\"High score but with red flags: liquidity={liquidity_usd}, safety={safety_score}\"\n",
        ")\n",
        "\n",
        "alert_manager.add_rule(suspicious_rule)\n",
        "\n",
        "print(\"‚úÖ Alert Engine v2 initialized with 3 rules\")\n",
        "print(f\"üìä Rules: {[r.id for r in alert_manager.rules.values()]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9edf98ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate alerts on scan results\n",
        "metrics_data = {\n",
        "    \"gem_score\": 25,\n",
        "    \"honeypot_detected\": True,\n",
        "    \"liquidity_usd\": 5000,\n",
        "    \"safety_score\": 0.3\n",
        "}\n",
        "\n",
        "print(\"\\nüîç Evaluating rules with test data:\")\n",
        "print(f\"   Metrics: {metrics_data}\\n\")\n",
        "\n",
        "# Check each rule\n",
        "fired_alerts = alert_manager.evaluate(metrics_data)\n",
        "\n",
        "print(f\"\\nüö® Alerts fired: {len(fired_alerts)}\")\n",
        "for alert in fired_alerts:\n",
        "    print(f\"\\n   Alert: {alert.rule_id}\")\n",
        "    print(f\"   Severity: {alert.severity}\")\n",
        "    print(f\"   Message: {alert.message}\")\n",
        "    print(f\"   Fingerprint: {alert.fingerprint[:16]}...\")\n",
        "    print(f\"   Status: {alert.status}\")\n",
        "\n",
        "# Show active alerts\n",
        "active = alert_manager.get_active_alerts()\n",
        "print(f\"\\nüìà Active alerts: {len(active)}\")\n",
        "\n",
        "# Example: Acknowledge an alert\n",
        "if fired_alerts:\n",
        "    first_alert = fired_alerts[0]\n",
        "    alert_manager.acknowledge_alert(first_alert.id, \"Investigating via notebook\")\n",
        "    print(f\"\\n‚úÖ Acknowledged alert: {first_alert.id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89cd41ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alert Suppression - Prevent duplicate alerts\n",
        "print(\"\\nüîá Testing Alert Suppression\\n\")\n",
        "\n",
        "# Create suppression rule\n",
        "suppression = SuppressionRule(\n",
        "    pattern=r\".*test.*\",\n",
        "    field=\"token_name\",\n",
        "    duration=timedelta(hours=1)\n",
        ")\n",
        "\n",
        "alert_manager.add_suppression_rule(suppression)\n",
        "\n",
        "# Test with same metrics again (should be suppressed due to deduplication)\n",
        "print(\"1Ô∏è‚É£ First evaluation:\")\n",
        "alerts1 = alert_manager.evaluate(metrics_data)\n",
        "print(f\"   Fired: {len(alerts1)} alerts\")\n",
        "\n",
        "print(\"\\n2Ô∏è‚É£ Second evaluation (same metrics):\")\n",
        "alerts2 = alert_manager.evaluate(metrics_data)\n",
        "print(f\"   Fired: {len(alerts2)} alerts (should be 0 - suppressed)\")\n",
        "\n",
        "# Show suppression stats\n",
        "from src.core.metrics import ALERTS_SUPPRESSED\n",
        "print(f\"\\nüìä Total alerts suppressed: {ALERTS_SUPPRESSED._value.get()}\")\n",
        "\n",
        "# Different metrics should trigger new alerts\n",
        "print(\"\\n3Ô∏è‚É£ Third evaluation (different metrics):\")\n",
        "different_metrics = {\n",
        "    \"gem_score\": 20,  # Changed\n",
        "    \"honeypot_detected\": False,  # Changed\n",
        "    \"liquidity_usd\": 3000,\n",
        "    \"safety_score\": 0.2\n",
        "}\n",
        "alerts3 = alert_manager.evaluate(different_metrics)\n",
        "print(f\"   Fired: {len(alerts3)} alerts (new fingerprint)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95c88789",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escalation Policies - Tiered notifications\n",
        "print(\"\\nüì¢ Escalation Policy Example\\n\")\n",
        "\n",
        "# Create escalation policy\n",
        "escalation = EscalationPolicy(\n",
        "    levels=[\n",
        "        {\"delay\": timedelta(seconds=0), \"channels\": [\"slack\"]},\n",
        "        {\"delay\": timedelta(minutes=5), \"channels\": [\"telegram\"]},\n",
        "        {\"delay\": timedelta(minutes=15), \"channels\": [\"pagerduty\"]}\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create rule with escalation\n",
        "escalated_rule = AlertRule(\n",
        "    id=\"critical_with_escalation\",\n",
        "    name=\"Critical Alert with Escalation\",\n",
        "    condition=AlertCondition(\"gem_score\", \"lt\", 20),\n",
        "    severity=\"critical\",\n",
        "    escalation_policy=escalation,\n",
        "    message=\"Critical: GemScore below 20!\"\n",
        ")\n",
        "\n",
        "alert_manager.add_rule(escalated_rule)\n",
        "\n",
        "# Trigger the alert\n",
        "critical_metrics = {\"gem_score\": 15}\n",
        "escalated_alerts = alert_manager.evaluate(critical_metrics)\n",
        "\n",
        "if escalated_alerts:\n",
        "    alert = escalated_alerts[0]\n",
        "    print(f\"Alert: {alert.rule_id}\")\n",
        "    print(f\"Escalation levels: {len(alert.escalation_policy.levels)}\")\n",
        "    \n",
        "    for i, level in enumerate(alert.escalation_policy.levels):\n",
        "        print(f\"\\n   Level {i+1}:\")\n",
        "        print(f\"   - Delay: {level['delay']}\")\n",
        "        print(f\"   - Channels: {level['channels']}\")\n",
        "\n",
        "print(\"\\n‚úÖ Alert will escalate through 3 notification levels\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "529f8d3c",
      "metadata": {},
      "source": [
        "## üìä Drift Monitor MVP - Statistical Drift Detection\n",
        "\n",
        "Monitor data drift with statistical methods:\n",
        "- **Kolmogorov-Smirnov test** (continuous features)\n",
        "- **Population Stability Index (PSI)** (distribution shift)\n",
        "- **Chi-square test** (categorical features)\n",
        "- **Baseline management** (save/load reference distributions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1ec64d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Drift Monitor\n",
        "from src.monitoring.drift_monitor import DriftMonitor, DriftDetector, Baseline\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# Create drift monitor\n",
        "drift_monitor = DriftMonitor()\n",
        "\n",
        "# Generate synthetic baseline data (replace with real scan results)\n",
        "print(\"üîß Creating baseline from historical data...\\n\")\n",
        "\n",
        "# Simulate 1000 historical scans\n",
        "baseline_features = {\n",
        "    \"gem_score\": np.random.normal(60, 15, 1000).clip(0, 100),\n",
        "    \"liquidity_usd\": np.random.lognormal(10, 2, 1000),\n",
        "    \"holder_count\": np.random.poisson(500, 1000),\n",
        "    \"safety_score\": np.random.beta(5, 2, 1000)\n",
        "}\n",
        "\n",
        "baseline_predictions = np.random.normal(65, 20, 1000).clip(0, 100)\n",
        "\n",
        "# Create baseline\n",
        "baseline = Baseline(\n",
        "    features=baseline_features,\n",
        "    predictions=baseline_predictions.tolist()\n",
        ")\n",
        "\n",
        "# Save baseline for future use\n",
        "baseline_path = Path(\"artifacts/baselines/gem_scanner_baseline.json\")\n",
        "baseline_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "baseline.save(str(baseline_path))\n",
        "\n",
        "print(f\"‚úÖ Baseline created and saved to {baseline_path}\")\n",
        "print(f\"   Features: {list(baseline_features.keys())}\")\n",
        "print(f\"   Samples: {len(baseline_predictions)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f93e56d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detect Feature Drift\n",
        "print(\"\\nüìä Testing Feature Drift Detection\\n\")\n",
        "\n",
        "# Scenario 1: No drift - similar distribution\n",
        "print(\"1Ô∏è‚É£ Scenario: Normal market conditions (no drift)\")\n",
        "normal_features = {\n",
        "    \"gem_score\": np.random.normal(60, 15, 200).clip(0, 100),\n",
        "    \"liquidity_usd\": np.random.lognormal(10, 2, 200),\n",
        "    \"holder_count\": np.random.poisson(500, 200),\n",
        "    \"safety_score\": np.random.beta(5, 2, 200)\n",
        "}\n",
        "\n",
        "drift_report_1 = drift_monitor.detect_feature_drift(baseline, normal_features)\n",
        "\n",
        "print(f\"\\n   Drift detected: {drift_report_1.drift_detected}\")\n",
        "print(\"   Feature results:\")\n",
        "for feature, result in drift_report_1.feature_drift.items():\n",
        "    print(f\"   - {feature}:\")\n",
        "    print(f\"     KS statistic: {result.ks_statistic:.3f} (p={result.ks_p_value:.3f})\")\n",
        "    print(f\"     PSI: {result.psi:.3f}\")\n",
        "    print(f\"     Drift: {'‚ö†Ô∏è YES' if result.drift_detected else '‚úÖ NO'}\")\n",
        "\n",
        "# Scenario 2: Drift detected - shifted distribution\n",
        "print(\"\\n\\n2Ô∏è‚É£ Scenario: Market shift detected (drift expected)\")\n",
        "drifted_features = {\n",
        "    \"gem_score\": np.random.normal(40, 15, 200).clip(0, 100),  # Lower mean\n",
        "    \"liquidity_usd\": np.random.lognormal(8, 2, 200),  # Lower liquidity\n",
        "    \"holder_count\": np.random.poisson(300, 200),  # Fewer holders\n",
        "    \"safety_score\": np.random.beta(2, 5, 200)  # Lower safety\n",
        "}\n",
        "\n",
        "drift_report_2 = drift_monitor.detect_feature_drift(baseline, drifted_features)\n",
        "\n",
        "print(f\"\\n   Drift detected: {drift_report_2.drift_detected}\")\n",
        "print(\"   Feature results:\")\n",
        "for feature, result in drift_report_2.feature_drift.items():\n",
        "    print(f\"   - {feature}:\")\n",
        "    print(f\"     KS statistic: {result.ks_statistic:.3f} (p={result.ks_p_value:.3f})\")\n",
        "    print(f\"     PSI: {result.psi:.3f}\")\n",
        "    print(f\"     Drift: {'‚ö†Ô∏è YES' if result.drift_detected else '‚úÖ NO'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f7976df",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detect Prediction Drift\n",
        "print(\"\\nüéØ Testing Prediction Drift Detection\\n\")\n",
        "\n",
        "# Normal predictions (similar to baseline)\n",
        "normal_predictions = np.random.normal(65, 20, 200).clip(0, 100)\n",
        "\n",
        "pred_report_1 = drift_monitor.detect_prediction_drift(baseline, normal_predictions.tolist())\n",
        "\n",
        "print(\"1Ô∏è‚É£ Normal predictions:\")\n",
        "print(f\"   Drift detected: {pred_report_1.drift_detected}\")\n",
        "print(f\"   KS statistic: {pred_report_1.prediction_drift.ks_statistic:.3f}\")\n",
        "print(f\"   KS p-value: {pred_report_1.prediction_drift.ks_p_value:.3f}\")\n",
        "print(f\"   PSI: {pred_report_1.prediction_drift.psi:.3f}\")\n",
        "\n",
        "# Drifted predictions (different distribution)\n",
        "drifted_predictions = np.random.normal(45, 25, 200).clip(0, 100)  # Lower mean, higher variance\n",
        "\n",
        "pred_report_2 = drift_monitor.detect_prediction_drift(baseline, drifted_predictions.tolist())\n",
        "\n",
        "print(\"\\n2Ô∏è‚É£ Drifted predictions:\")\n",
        "print(f\"   Drift detected: {pred_report_2.drift_detected}\")\n",
        "print(f\"   KS statistic: {pred_report_2.prediction_drift.ks_statistic:.3f}\")\n",
        "print(f\"   KS p-value: {pred_report_2.prediction_drift.ks_p_value:.3f}\")\n",
        "print(f\"   PSI: {pred_report_2.prediction_drift.psi:.3f}\")\n",
        "\n",
        "# Statistical interpretation\n",
        "if pred_report_2.drift_detected:\n",
        "    print(\"\\n   ‚ö†Ô∏è DRIFT ALERT:\")\n",
        "    print(\"   - Model predictions have shifted significantly\")\n",
        "    print(\"   - Possible causes: market regime change, data quality issues\")\n",
        "    print(\"   - Action: Review recent predictions, retrain model if needed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaef07b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive Drift Report with Visualization\n",
        "print(\"\\nüìà Comprehensive Drift Analysis\\n\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Full drift detection\n",
        "full_report = drift_monitor.detect_drift(\n",
        "    baseline=baseline,\n",
        "    current_features=drifted_features,\n",
        "    current_predictions=drifted_predictions.tolist()\n",
        ")\n",
        "\n",
        "# Print summary\n",
        "print(\"=\" * 60)\n",
        "print(f\"DRIFT REPORT - {full_report.timestamp}\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nOverall Drift Detected: {full_report.drift_detected}\")\n",
        "print(f\"Total Features Checked: {len(full_report.feature_drift)}\")\n",
        "print(f\"Features with Drift: {sum(1 for r in full_report.feature_drift.values() if r.drift_detected)}\")\n",
        "\n",
        "# Detailed breakdown\n",
        "print(\"\\n\" + \"-\" * 60)\n",
        "print(\"FEATURE DRIFT DETAILS\")\n",
        "print(\"-\" * 60)\n",
        "for feature, result in full_report.feature_drift.items():\n",
        "    status = \"üî¥ DRIFT\" if result.drift_detected else \"üü¢ STABLE\"\n",
        "    print(f\"\\n{feature}: {status}\")\n",
        "    print(f\"  KS Test: stat={result.ks_statistic:.3f}, p={result.ks_p_value:.4f}\")\n",
        "    print(f\"  PSI: {result.psi:.3f} ({'HIGH' if result.psi > 0.2 else 'MEDIUM' if result.psi > 0.1 else 'LOW'})\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 60)\n",
        "print(\"PREDICTION DRIFT\")\n",
        "print(\"-\" * 60)\n",
        "pred = full_report.prediction_drift\n",
        "status = \"üî¥ DRIFT\" if pred.drift_detected else \"üü¢ STABLE\"\n",
        "print(f\"Status: {status}\")\n",
        "print(f\"KS Test: stat={pred.ks_statistic:.3f}, p={pred.ks_p_value:.4f}\")\n",
        "print(f\"PSI: {pred.psi:.3f}\")\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "fig.suptitle('Drift Detection Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Plot 1: KS Statistics\n",
        "features = list(full_report.feature_drift.keys())\n",
        "ks_stats = [full_report.feature_drift[f].ks_statistic for f in features]\n",
        "colors = ['red' if full_report.feature_drift[f].drift_detected else 'green' for f in features]\n",
        "\n",
        "axes[0, 0].bar(range(len(features)), ks_stats, color=colors, alpha=0.7)\n",
        "axes[0, 0].axhline(y=0.1, color='orange', linestyle='--', label='Threshold')\n",
        "axes[0, 0].set_xticks(range(len(features)))\n",
        "axes[0, 0].set_xticklabels(features, rotation=45, ha='right')\n",
        "axes[0, 0].set_ylabel('KS Statistic')\n",
        "axes[0, 0].set_title('Kolmogorov-Smirnov Test Results')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: PSI Scores\n",
        "psi_scores = [full_report.feature_drift[f].psi for f in features]\n",
        "axes[0, 1].bar(range(len(features)), psi_scores, color=colors, alpha=0.7)\n",
        "axes[0, 1].axhline(y=0.1, color='yellow', linestyle='--', label='Low threshold')\n",
        "axes[0, 1].axhline(y=0.2, color='orange', linestyle='--', label='High threshold')\n",
        "axes[0, 1].set_xticks(range(len(features)))\n",
        "axes[0, 1].set_xticklabels(features, rotation=45, ha='right')\n",
        "axes[0, 1].set_ylabel('PSI Score')\n",
        "axes[0, 1].set_title('Population Stability Index')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: Distribution comparison (gem_score)\n",
        "axes[1, 0].hist(baseline.features['gem_score'], bins=30, alpha=0.5, label='Baseline', color='blue')\n",
        "axes[1, 0].hist(drifted_features['gem_score'], bins=30, alpha=0.5, label='Current', color='red')\n",
        "axes[1, 0].set_xlabel('GemScore')\n",
        "axes[1, 0].set_ylabel('Frequency')\n",
        "axes[1, 0].set_title('Feature Distribution: gem_score')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 4: Prediction distribution\n",
        "axes[1, 1].hist(baseline.predictions, bins=30, alpha=0.5, label='Baseline', color='blue')\n",
        "axes[1, 1].hist(drifted_predictions, bins=30, alpha=0.5, label='Current', color='red')\n",
        "axes[1, 1].set_xlabel('Prediction Value')\n",
        "axes[1, 1].set_ylabel('Frequency')\n",
        "axes[1, 1].set_title('Prediction Distribution')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úÖ Drift analysis complete with visualizations\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
