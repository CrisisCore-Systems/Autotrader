{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "051fe605",
      "metadata": {},
      "source": [
        "# VoidBloom / CrisisCore Enhanced Prototype Notebook\n",
        "\n",
        "This notebook demonstrates the complete Hidden-Gem Scanner pipeline with:\n",
        "- **Provenance Tracking**: Full lineage tracking of all artifacts and transformations\n",
        "- **Glossary Generation**: Automatic documentation of technical terms and metrics\n",
        "- **Feature Extraction**: Time series analysis and market data processing\n",
        "- **GemScore Calculation**: Weighted scoring with confidence metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dd0fdd1",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from src.core.features import MarketSnapshot\n",
        "from src.core.safety import evaluate_contract, liquidity_guardrail\n",
        "from src.core.provenance_tracking import complete_pipeline_tracked\n",
        "from src.core.provenance import get_provenance_tracker, reset_provenance_tracker\n",
        "from src.core.glossary import get_glossary\n",
        "\n",
        "# Reset tracker for clean demo\n",
        "reset_provenance_tracker()\n",
        "\n",
        "print(\"✅ Imports complete\")\n",
        "print(f\"📊 Provenance tracker ready\")\n",
        "print(f\"📖 Glossary contains {len(get_glossary().terms)} terms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "985b9c6d",
      "metadata": {},
      "source": [
        "## 2. Create Synthetic Market Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09de7bdb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create synthetic price series showing uptrend\n",
        "now = datetime.utcnow()\n",
        "dates = [now - timedelta(hours=i) for i in range(48)][::-1]\n",
        "prices = pd.Series(\n",
        "    data=[0.03 + 0.0002 * i for i in range(48)],\n",
        "    index=pd.to_datetime(dates)\n",
        ")\n",
        "\n",
        "# Create market snapshot\n",
        "snapshot = MarketSnapshot(\n",
        "    symbol=\"VBLOOM\",\n",
        "    timestamp=now,\n",
        "    price=float(prices.iloc[-1]),\n",
        "    volume_24h=250000,\n",
        "    liquidity_usd=180000,\n",
        "    holders=4200,\n",
        "    onchain_metrics={\"active_wallets\": 950, \"net_inflows\": 125000, \"unlock_pressure\": 0.2},\n",
        "    narratives=[\"AI\", \"DeFi\", \"VoidBloom\"]\n",
        ")\n",
        "\n",
        "# Create contract safety report\n",
        "contract_report = evaluate_contract(\n",
        "    {\"honeypot\": False, \"owner_can_mint\": False, \"owner_can_withdraw\": False, \"unverified\": False},\n",
        "    severity=\"none\"\n",
        ")\n",
        "\n",
        "print(f\"📈 Generated {len(prices)} price points for {snapshot.symbol}\")\n",
        "print(f\"💰 Current price: ${snapshot.price:.6f}\")\n",
        "print(f\"💧 Liquidity: ${snapshot.liquidity_usd:,.0f}\")\n",
        "print(f\"👥 Holders: {snapshot.holders:,}\")\n",
        "print(f\"🛡️ Contract safety score: {contract_report.score:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b05f6926",
      "metadata": {},
      "source": [
        "## 3. Execute Pipeline with Provenance Tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "621912c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute complete pipeline with provenance tracking\n",
        "results = complete_pipeline_tracked(\n",
        "    snapshot=snapshot,\n",
        "    price_series=prices,\n",
        "    narrative_embedding_score=0.72,\n",
        "    contract_report=contract_report,\n",
        "    data_source=\"synthetic_demo\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"📊 ANALYSIS RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\n💎 GemScore: {results['result'].score:.2f}\")\n",
        "print(f\"🎯 Confidence: {results['result'].confidence:.2f}%\")\n",
        "print(f\"🚩 Flagged for Review: {results['flagged']}\")\n",
        "print(f\"\\n📋 Feature Contributions:\")\n",
        "for feature, contribution in sorted(results['result'].contributions.items(), key=lambda x: -x[1]):\n",
        "    print(f\"  - {feature}: {contribution:.4f}\")\n",
        "\n",
        "print(f\"\\n🔍 Debug Info:\")\n",
        "for key, value in results['debug'].items():\n",
        "    print(f\"  - {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47257eef",
      "metadata": {},
      "source": [
        "## 4. Explore Artifact Provenance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ff32a56",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get provenance information\n",
        "tracker = get_provenance_tracker()\n",
        "score_id = results['provenance']['score_id']\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"🔍 ARTIFACT PROVENANCE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Get the score record\n",
        "score_record = tracker.get_record(score_id)\n",
        "if score_record:\n",
        "    print(f\"\\n📦 Artifact: {score_record.artifact.name}\")\n",
        "    print(f\"🆔 ID: {score_id[:16]}...\")\n",
        "    print(f\"📅 Created: {score_record.artifact.created_at.strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
        "    print(f\"🏷️ Tags: {', '.join(score_record.artifact.tags)}\")\n",
        "    \n",
        "    print(f\"\\n🔄 Transformations Applied:\")\n",
        "    for i, transform in enumerate(score_record.transformations, 1):\n",
        "        print(f\"  {i}. {transform.function_name} ({transform.transformation_type.value})\")\n",
        "        print(f\"     ⏱️ Duration: {transform.duration_ms:.2f}ms\")\n",
        "    \n",
        "    print(f\"\\n📊 Quality Metrics:\")\n",
        "    for metric, value in list(score_record.quality_metrics.items())[:5]:\n",
        "        print(f\"  - {metric}: {value:.4f}\")\n",
        "    \n",
        "    if score_record.annotations:\n",
        "        print(f\"\\n💬 Annotations:\")\n",
        "        for annotation in score_record.annotations:\n",
        "            print(f\"  - {annotation}\")\n",
        "\n",
        "# Get complete lineage\n",
        "lineage = tracker.get_lineage(score_id)\n",
        "print(f\"\\n🌳 Lineage Depth: {len(lineage)} artifacts\")\n",
        "print(f\"📈 Artifact chain:\")\n",
        "for i, artifact_id in enumerate(lineage):\n",
        "    record = tracker.get_record(artifact_id)\n",
        "    if record:\n",
        "        print(f\"  {i+1}. {record.artifact.artifact_type.value}: {record.artifact.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75102dea",
      "metadata": {},
      "source": [
        "## 5. Visualize Lineage Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9a13264",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export lineage as Mermaid diagram\n",
        "mermaid_diagram = tracker.export_lineage_graph(score_id, format=\"mermaid\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"🎨 LINEAGE DIAGRAM (Mermaid)\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nCopy this to https://mermaid.live for visualization:\\n\")\n",
        "print(mermaid_diagram)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# Get tracker statistics\n",
        "stats = tracker.get_statistics()\n",
        "print(\"\\n📊 PROVENANCE STATISTICS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Total Artifacts: {stats['total_artifacts']}\")\n",
        "print(f\"Total Transformations: {stats['total_transformations']}\")\n",
        "print(f\"Lineage Edges: {stats['lineage_edges']}\")\n",
        "print(f\"\\nArtifacts by Type:\")\n",
        "for artifact_type, count in stats['artifacts_by_type'].items():\n",
        "    print(f\"  - {artifact_type}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a8d6c65",
      "metadata": {},
      "source": [
        "## 6. Explore Technical Glossary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf41a49c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explore the glossary\n",
        "glossary = get_glossary()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"📖 TECHNICAL GLOSSARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Get glossary statistics\n",
        "glossary_stats = glossary.get_statistics()\n",
        "print(f\"\\nTotal Terms: {glossary_stats['total_terms']}\")\n",
        "print(f\"Categories: {glossary_stats['categories_count']}\")\n",
        "print(f\"\\nTerms by Category:\")\n",
        "for category, count in glossary_stats['category_breakdown'].items():\n",
        "    print(f\"  - {category}: {count}\")\n",
        "\n",
        "# Show some key terms\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"📚 SAMPLE TERMS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "key_terms = [\"GemScore\", \"RSI\", \"ContractSafety\", \"Confidence\"]\n",
        "for term_name in key_terms:\n",
        "    term = glossary.get_term(term_name)\n",
        "    if term:\n",
        "        print(f\"\\n{term.term}\")\n",
        "        print(\"-\" * 40)\n",
        "        print(f\"Category: {term.category.value}\")\n",
        "        print(f\"Definition: {term.definition}\")\n",
        "        if term.formula:\n",
        "            print(f\"Formula: {term.formula}\")\n",
        "        if term.range:\n",
        "            print(f\"Range: [{term.range[0]}, {term.range[1]}]\")\n",
        "        if term.related_terms:\n",
        "            print(f\"Related: {', '.join(list(term.related_terms)[:3])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ec7c2e8",
      "metadata": {},
      "source": [
        "## 7. Search Glossary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59918c1a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Search for terms related to risk\n",
        "search_results = glossary.search(\"risk\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"🔍 SEARCH RESULTS: 'risk'\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for term in search_results:\n",
        "    print(f\"\\n✓ {term.term} ({term.category.value})\")\n",
        "    print(f\"  {term.definition[:100]}...\")\n",
        "\n",
        "# Get all terms in a specific category\n",
        "from src.core.glossary import TermCategory\n",
        "\n",
        "risk_factors = glossary.get_by_category(TermCategory.RISK_FACTOR)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"⚠️ ALL RISK FACTORS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for term in risk_factors:\n",
        "    print(f\"\\n• {term.term}\")\n",
        "    print(f\"  {term.definition}\")\n",
        "    if term.range:\n",
        "        print(f\"  Range: [{term.range[0]}, {term.range[1]}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e83e5080",
      "metadata": {},
      "source": [
        "## 8. Export Documentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c29ecf8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Export glossary as markdown\n",
        "docs_dir = Path(\"../docs\")\n",
        "docs_dir.mkdir(exist_ok=True)\n",
        "\n",
        "glossary_path = docs_dir / \"GLOSSARY.md\"\n",
        "glossary_markdown = glossary.export_markdown(output_path=glossary_path, include_toc=True, group_by_category=True)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"📄 EXPORTED DOCUMENTATION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\n✅ Glossary exported to: {glossary_path}\")\n",
        "print(f\"📏 Document size: {len(glossary_markdown)} characters\")\n",
        "\n",
        "# Export as JSON for programmatic access\n",
        "glossary_json_path = docs_dir / \"glossary.json\"\n",
        "glossary_json = glossary.export_json(output_path=glossary_json_path)\n",
        "\n",
        "print(f\"✅ JSON export to: {glossary_json_path}\")\n",
        "\n",
        "# Show preview of markdown\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"📄 GLOSSARY PREVIEW (first 500 chars)\")\n",
        "print(\"=\" * 60)\n",
        "print(glossary_markdown[:500] + \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f053c7e6",
      "metadata": {},
      "source": [
        "## 9. Extended Backtest Metrics (IC & Risk-Adjusted Performance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "244de76c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from backtest.extended_metrics import (\n",
        "    calculate_extended_metrics,\n",
        "    calculate_ic_metrics,\n",
        "    format_ic_summary,\n",
        ")\n",
        "\n",
        "# Create synthetic backtest data\n",
        "# Simulate 50 token snapshots with predictions and actual returns\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate predictions (GemScores)\n",
        "predictions = np.random.uniform(0.3, 0.9, 50)\n",
        "\n",
        "# Generate actual returns with some correlation to predictions\n",
        "actual_returns = predictions * 0.05 + np.random.normal(0, 0.02, 50)\n",
        "\n",
        "# Create mock snapshots\n",
        "class MockSnapshot:\n",
        "    def __init__(self, token, features, future_return):\n",
        "        self.token = token\n",
        "        self.features = features\n",
        "        self.future_return_7d = future_return\n",
        "\n",
        "snapshots = [\n",
        "    MockSnapshot(f\"TOKEN{i:02d}\", {}, actual_returns[i])\n",
        "    for i in range(50)\n",
        "]\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"📊 SYNTHETIC BACKTEST DATA\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Total Snapshots: {len(snapshots)}\")\n",
        "print(f\"Prediction Range: [{predictions.min():.4f}, {predictions.max():.4f}]\")\n",
        "print(f\"Return Range: [{actual_returns.min():.4f}, {actual_returns.max():.4f}]\")\n",
        "print(f\"Mean Return: {actual_returns.mean():.4f}\")\n",
        "print(f\"Return Std Dev: {actual_returns.std():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c97588e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate Information Coefficient (IC) metrics\n",
        "ic_metrics = calculate_ic_metrics(predictions, actual_returns)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"📈 INFORMATION COEFFICIENT ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "print(format_ic_summary(ic_metrics))\n",
        "\n",
        "# Interpretation\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"🔍 IC INTERPRETATION\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "The Information Coefficient measures the correlation between predicted\n",
        "scores and actual returns. Key insights:\n",
        "\n",
        "1. **Pearson IC**: Measures linear correlation\n",
        "   - IC > 0.05: Strong predictive power\n",
        "   - IC > 0.02: Moderate predictive power\n",
        "   - IC < 0.02: Weak predictive power\n",
        "\n",
        "2. **Spearman IC**: Measures rank correlation (robust to outliers)\n",
        "   - Useful when returns are skewed or have outliers\n",
        "\n",
        "3. **Kendall's Tau**: Alternative rank correlation\n",
        "   - More conservative than Spearman\n",
        "\n",
        "4. **Hit Rate**: Percentage of correct direction predictions\n",
        "   - > 55%: Better than random for direction\n",
        "   - > 60%: Strong directional signal\n",
        "\n",
        "5. **IC IR (Information Ratio)**: IC_mean / IC_std\n",
        "   - Measures consistency of IC across periods\n",
        "   - Higher is better (more stable predictions)\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0eb5e30",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate comprehensive extended metrics\n",
        "extended_metrics = calculate_extended_metrics(\n",
        "    snapshots=snapshots,\n",
        "    predictions=predictions,\n",
        "    top_k=10,  # Evaluate top 10 predictions\n",
        "    risk_free_rate=0.0,\n",
        "    periods_per_year=52,  # Weekly returns\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"💰 COMPREHENSIVE BACKTEST METRICS\")\n",
        "print(\"=\" * 70)\n",
        "print(extended_metrics.summary_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cf94d87",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare with baseline strategies\n",
        "from backtest.baseline_strategies import (\n",
        "    RandomStrategy,\n",
        "    CapWeightedStrategy,\n",
        "    SimpleMomentumStrategy,\n",
        ")\n",
        "from backtest.extended_metrics import compare_extended_metrics\n",
        "\n",
        "# Add market cap and momentum features to snapshots for baseline comparison\n",
        "for i, snap in enumerate(snapshots):\n",
        "    snap.features = {\n",
        "        'MarketCap': np.random.uniform(100000, 10000000),\n",
        "        'PriceChange7d': np.random.uniform(-0.1, 0.2),\n",
        "    }\n",
        "\n",
        "# Calculate baseline metrics\n",
        "baseline_strategies = [\n",
        "    RandomStrategy(),\n",
        "    CapWeightedStrategy(),\n",
        "    SimpleMomentumStrategy(),\n",
        "]\n",
        "\n",
        "baseline_metrics = {}\n",
        "for strategy in baseline_strategies:\n",
        "    # Select assets using baseline strategy\n",
        "    selected = strategy.select_assets(snapshots, top_k=10, seed=42)\n",
        "    \n",
        "    # Get predictions (uniform for baselines)\n",
        "    baseline_predictions = np.array([1.0 if snap in selected else 0.0 for snap in snapshots])\n",
        "    \n",
        "    # Calculate metrics\n",
        "    baseline_metrics[strategy.get_name()] = calculate_extended_metrics(\n",
        "        snapshots=snapshots,\n",
        "        predictions=baseline_predictions,\n",
        "        top_k=10,\n",
        "        risk_free_rate=0.0,\n",
        "        periods_per_year=52,\n",
        "    )\n",
        "\n",
        "# Compare GemScore to baselines\n",
        "comparisons = compare_extended_metrics(extended_metrics, baseline_metrics)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"🎯 BASELINE COMPARISONS\")\n",
        "print(\"=\" * 70)\n",
        "for baseline_name, comparison in comparisons.items():\n",
        "    print(f\"\\n{baseline_name.replace('_', ' ').title()}:\")\n",
        "    print(f\"  IC Improvement:     {comparison['ic_improvement']:>8.4f}  {'✅' if comparison['ic_better'] else '❌'}\")\n",
        "    print(f\"  Sharpe Improvement: {comparison['sharpe_improvement']:>8.4f}  {'✅' if comparison['sharpe_better'] else '❌'}\")\n",
        "    print(f\"  Sortino Improvement:{comparison['sortino_improvement']:>8.4f}\")\n",
        "    print(f\"  Return Improvement: {comparison['return_improvement']:>8.4f}\")\n",
        "    print(f\"  Risk-Adjusted Better: {'✅ YES' if comparison['risk_adjusted_better'] else '❌ NO'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "796f2cc0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize IC distribution over multiple periods\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Simulate multi-period IC\n",
        "np.random.seed(42)\n",
        "n_periods = 20\n",
        "period_ics = []\n",
        "\n",
        "for period in range(n_periods):\n",
        "    # Generate predictions and actuals for each period\n",
        "    period_preds = np.random.uniform(0.3, 0.9, 30)\n",
        "    period_actuals = period_preds * 0.05 + np.random.normal(0, 0.025, 30)\n",
        "    \n",
        "    # Calculate IC for this period\n",
        "    from scipy import stats\n",
        "    ic, _ = stats.pearsonr(period_preds, period_actuals)\n",
        "    period_ics.append(ic)\n",
        "\n",
        "# Create visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# IC over time\n",
        "axes[0, 0].plot(range(1, n_periods + 1), period_ics, marker='o', linewidth=2)\n",
        "axes[0, 0].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
        "axes[0, 0].axhline(y=0.02, color='orange', linestyle='--', alpha=0.5, label='Moderate IC')\n",
        "axes[0, 0].axhline(y=0.05, color='green', linestyle='--', alpha=0.5, label='Strong IC')\n",
        "axes[0, 0].set_xlabel('Period')\n",
        "axes[0, 0].set_ylabel('Information Coefficient')\n",
        "axes[0, 0].set_title('IC Over Time')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# IC distribution\n",
        "axes[0, 1].hist(period_ics, bins=15, edgecolor='black', alpha=0.7)\n",
        "axes[0, 1].axvline(x=np.mean(period_ics), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(period_ics):.4f}')\n",
        "axes[0, 1].set_xlabel('Information Coefficient')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "axes[0, 1].set_title('IC Distribution')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# Predictions vs Actuals scatter\n",
        "axes[1, 0].scatter(predictions[:30], actual_returns[:30], alpha=0.6)\n",
        "axes[1, 0].plot([predictions.min(), predictions.max()], \n",
        "                [predictions.min() * 0.05, predictions.max() * 0.05], \n",
        "                'r--', label='Expected Relationship')\n",
        "axes[1, 0].set_xlabel('Predicted Score')\n",
        "axes[1, 0].set_ylabel('Actual Return')\n",
        "axes[1, 0].set_title('Predictions vs Actual Returns')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "# Cumulative returns\n",
        "cumulative_returns = np.cumsum(actual_returns[:30])\n",
        "axes[1, 1].plot(range(1, 31), cumulative_returns, linewidth=2)\n",
        "axes[1, 1].fill_between(range(1, 31), 0, cumulative_returns, alpha=0.3)\n",
        "axes[1, 1].set_xlabel('Asset Index (sorted by GemScore)')\n",
        "axes[1, 1].set_ylabel('Cumulative Return')\n",
        "axes[1, 1].set_title('Cumulative Returns (Top 30)')\n",
        "axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../docs/ic_analysis.png', dpi=150, bbox_inches='tight')\n",
        "print(\"📊 Visualization saved to: ../docs/ic_analysis.png\")\n",
        "plt.show()\n",
        "\n",
        "# Print IC statistics\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"📊 IC STATISTICS (Multi-Period)\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Mean IC:        {np.mean(period_ics):>8.4f}\")\n",
        "print(f\"Median IC:      {np.median(period_ics):>8.4f}\")\n",
        "print(f\"Std Dev IC:     {np.std(period_ics):>8.4f}\")\n",
        "print(f\"IC IR:          {np.mean(period_ics) / np.std(period_ics):>8.4f}\")\n",
        "print(f\"Min IC:         {np.min(period_ics):>8.4f}\")\n",
        "print(f\"Max IC:         {np.max(period_ics):>8.4f}\")\n",
        "print(f\"Positive ICs:   {sum(ic > 0 for ic in period_ics)}/{n_periods} ({100 * sum(ic > 0 for ic in period_ics) / n_periods:.1f}%)\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
