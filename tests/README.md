# VoidBloom Testing Suite ğŸ§ª

Comprehensive testing suite for the VoidBloom AutoTrader cryptocurrency analysis platform.

## ğŸ“š Test Organization

### Test Structure
```
tests/
â”œâ”€â”€ conftest.py                      # Pytest configuration and fixtures
â”œâ”€â”€ stubs.py                         # Mock objects for testing
â”‚
â”œâ”€â”€ test_api_integration.py          # API endpoint integration tests (15 endpoints)
â”œâ”€â”€ test_core_services.py            # Core service unit tests
â”œâ”€â”€ test_enhanced_modules.py         # Enhanced module tests (SLA, circuit breakers, cache)
â”œâ”€â”€ test_e2e_workflows.py            # End-to-end workflow tests
â”œâ”€â”€ test_performance.py              # Performance and stress tests
â”‚
â”œâ”€â”€ test_alerting.py                 # Alert system tests
â”œâ”€â”€ test_dashboard_api.py            # Dashboard API tests
â”œâ”€â”€ test_features.py                 # Feature engineering tests
â”œâ”€â”€ test_llm_guardrails.py          # LLM budget and caching tests
â”œâ”€â”€ test_narrative.py                # Narrative analysis tests
â”œâ”€â”€ test_news.py                     # News aggregation tests
â”œâ”€â”€ test_pipeline.py                 # Scanning pipeline tests
â”œâ”€â”€ test_safety.py                   # Safety analysis tests
â”œâ”€â”€ test_scoring.py                  # Gem score calculation tests
â””â”€â”€ test_tree.py                     # Execution tree tests
```

## ğŸš€ Quick Start

### Run All Tests
```bash
pytest
```

### Run Specific Test Categories

#### API Integration Tests
```bash
pytest tests/test_api_integration.py -v
```

#### Core Services Tests
```bash
pytest tests/test_core_services.py -v
```

#### Enhanced Modules Tests
```bash
pytest tests/test_enhanced_modules.py -v
```

#### End-to-End Workflow Tests
```bash
pytest tests/test_e2e_workflows.py -v
```

#### Performance Tests
```bash
pytest tests/test_performance.py -v
```

### Run Tests by Marker
```bash
# Run only fast tests
pytest -m "not slow"

# Run only unit tests
pytest -m "unit"

# Run only integration tests
pytest -m "integration"

# Run only performance tests
pytest -m "performance"
```

## ğŸ“Š Test Coverage

### Generate Coverage Report
```bash
# Run tests with coverage
pytest --cov=src --cov-report=html --cov-report=term

# View HTML report
# Open htmlcov/index.html in browser
```

### Coverage Goals
- **Target**: 75% minimum coverage
- **Critical paths**: 90%+ coverage
- **API endpoints**: 100% coverage

## ğŸ§© Test Categories

### 1. API Integration Tests (`test_api_integration.py`)
Tests all 15 API endpoints:
- âœ… Root & Health endpoints
- âœ… Scanner endpoints (`/api/tokens`, `/api/tokens/{symbol}`)
- âœ… Anomaly detection endpoints
- âœ… Confidence interval endpoints
- âœ… SLA monitoring endpoints
- âœ… Analytics endpoints (correlation, orderflow, sentiment)
- âœ… Feature store endpoints
- âœ… Error handling & CORS

**Coverage**: All API endpoints with success, error, and edge cases

### 2. Core Services Tests (`test_core_services.py`)
Unit tests for core functionality:
- âœ… Sentiment analysis (with/without LLM)
- âœ… Feature engineering and transforms
- âœ… Reliability services (SLA registry, circuit breakers)
- âœ… Feature store (read/write/schema)
- âœ… News client
- âœ… Pipeline components
- âœ… Safety analysis

**Coverage**: Core business logic and data processing

### 3. Enhanced Modules Tests (`test_enhanced_modules.py`)
Tests for advanced reliability features:
- âœ… SLA monitoring (metrics, status transitions)
- âœ… Circuit breaker (state transitions, recovery)
- âœ… Cache policies (TTL, adaptive caching)
- âœ… OrderFlow clients (Binance, Bybit)
- âœ… Twitter API client
- âœ… Sentiment extraction

**Coverage**: Reliability infrastructure and external integrations

### 4. End-to-End Workflow Tests (`test_e2e_workflows.py`)
Complete system workflows:
- âœ… Full token scanning pipeline
- âœ… Execution tree construction
- âœ… Feature extraction pipeline
- âœ… Scoring calculation workflow
- âœ… Multi-source data aggregation
- âœ… Batch processing
- âœ… Error recovery and resilience

**Coverage**: Complete user journeys and data flows

### 5. Performance Tests (`test_performance.py`)
System performance and load testing:
- âœ… API response times
- âœ… Concurrent request handling
- âœ… Sustained load testing
- âœ… Cache performance
- âœ… Memory stability
- âœ… Circuit breaker under load
- âœ… Benchmarks for key operations

**Coverage**: Performance SLAs and system limits

## ğŸ› ï¸ Test Utilities

### Fixtures (in `conftest.py`)
```python
# Common test fixtures
- pytest_configure()        # Setup test environment
- token_config              # Sample token configuration
- scanner                   # Scanner instance
- feature_store             # Feature store instance
- sla_monitor              # SLA monitor instance
- circuit_breaker          # Circuit breaker instance
- cache_policy             # Cache policy instance
```

### Mocks (in `stubs.py`)
```python
# Mock objects for testing
- StubGroqClient           # Mock LLM client
- StubAPIResponse          # Mock API responses
- StubDatabase            # Mock database
```

## ğŸ“ Writing Tests

### Test Naming Convention
```python
def test_{feature}_{scenario}():
    """Test that {feature} {expected behavior} when {scenario}."""
    # Arrange
    ...
    
    # Act
    ...
    
    # Assert
    ...
```

### Example Test
```python
def test_sentiment_analysis_with_positive_news():
    """Test sentiment analysis returns positive score for bullish news."""
    # Arrange
    analyzer = SentimentAnalyzer()
    articles = [
        {"title": "Bitcoin surges to new highs", "sentiment": 8},
        {"title": "Bullish market momentum", "sentiment": 7}
    ]
    
    # Act
    result = analyzer.analyze_news_sentiment("BTC", articles)
    
    # Assert
    assert 0.5 < result <= 1.0  # Should be positive
```

### Using Mocks
```python
from unittest.mock import patch, Mock

@patch('src.core.clients.requests.get')
def test_api_call_with_mock(mock_get):
    """Test API call using mocked response."""
    # Setup mock
    mock_response = Mock()
    mock_response.json.return_value = {"price": 50000}
    mock_response.status_code = 200
    mock_get.return_value = mock_response
    
    # Test code here
    ...
```

## ğŸ¯ Testing Best Practices

### 1. **Test Independence**
- Each test should be independent
- No shared state between tests
- Use fixtures for setup/teardown

### 2. **Clear Assertions**
- Use descriptive assertion messages
- Test one thing per test function
- Use pytest's rich assertion introspection

### 3. **Mock External Dependencies**
- Mock API calls to external services
- Mock database operations
- Use dependency injection

### 4. **Performance Considerations**
- Mark slow tests with `@pytest.mark.slow`
- Use mocks for expensive operations
- Run performance tests separately

### 5. **Error Testing**
- Test error conditions
- Test edge cases
- Test invalid inputs

## ğŸ› Debugging Tests

### Run with Verbose Output
```bash
pytest -vv
```

### Run with Print Statements
```bash
pytest -s
```

### Run Specific Test
```bash
pytest tests/test_file.py::test_function_name
```

### Drop into Debugger on Failure
```bash
pytest --pdb
```

### Show Local Variables on Failure
```bash
pytest -l
```

## ğŸ”„ Continuous Integration

### Pre-commit Checks
```bash
# Run before committing
pytest --maxfail=1  # Stop on first failure
pytest --cov=src --cov-fail-under=75  # Ensure coverage threshold
```

### CI Pipeline Tests
```bash
# Full test suite
pytest --cov=src --cov-report=xml --junitxml=test-results.xml
```

## ğŸ“ˆ Test Metrics

### Current Test Statistics
- **Total Test Files**: 20
- **Total Test Cases**: 250+
- **API Endpoint Coverage**: 15/15 (100%)
- **Code Coverage Target**: 75%
- **Performance Tests**: 30+
- **Integration Tests**: 80+
- **Unit Tests**: 140+

### Test Execution Time
- **Fast Tests** (<1s): ~70%
- **Medium Tests** (1-5s): ~25%
- **Slow Tests** (>5s): ~5%

## ğŸš¨ Common Issues & Solutions

### Issue: Tests fail due to missing API keys
**Solution**: Set environment variables or use mocks
```bash
export GROQ_API_KEY="test_key"
export COINGECKO_API_KEY="test_key"
```

### Issue: Tests timeout
**Solution**: Increase timeout or use mocks
```python
@pytest.mark.timeout(30)
def test_slow_operation():
    ...
```

### Issue: Flaky tests
**Solution**: Use `pytest-retry` or fix race conditions
```python
@pytest.mark.flaky(reruns=3)
def test_sometimes_fails():
    ...
```

## ğŸ“š Additional Resources

- [Pytest Documentation](https://docs.pytest.org/)
- [Python Testing Best Practices](https://docs.python-guide.org/writing/tests/)
- [FastAPI Testing](https://fastapi.tiangolo.com/tutorial/testing/)
- [Coverage.py Documentation](https://coverage.readthedocs.io/)

## ğŸ‰ Test Suite Features

âœ… **Comprehensive Coverage** - All major components tested  
âœ… **Fast Execution** - Optimized for quick feedback  
âœ… **Clear Organization** - Logical test structure  
âœ… **Good Documentation** - Each test is documented  
âœ… **Mocking Support** - External dependencies mocked  
âœ… **Performance Testing** - Load and stress tests included  
âœ… **CI/CD Ready** - Compatible with GitHub Actions  
âœ… **Error Scenarios** - Edge cases and errors covered  

---

**Happy Testing! ğŸš€**

For questions or issues, refer to the main project documentation or open an issue on GitHub.
